{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029ea819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e28c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "dfTest = pd.read_csv('test.csv')\n",
    "dataset = pd.read_csv('train.csv')\n",
    "\n",
    "dfe = pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f44cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af2c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dataset.isnull().sum().sum() == 0\n",
    "\n",
    "num_col_names = list(dataset.select_dtypes(include='number').columns)\n",
    "cat_col_names = list(set(dataset.columns) - set(num_col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd5f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=cat_col_names)\n",
    "tensor = torch.from_numpy(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99e440eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          1\n",
       "2          2\n",
       "3          3\n",
       "4          4\n",
       "        ... \n",
       "1672    1672\n",
       "1673    1673\n",
       "1674    1674\n",
       "1675    1675\n",
       "1676    1676\n",
       "Name: id, Length: 1677, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pop(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2d31c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.pop(\"Attrition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9911d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "sca = StandardScaler()\n",
    "df = sca.fit_transform(df)\n",
    "\n",
    "tensor = torch.from_numpy(df)\n",
    "labeltensor = torch.from_numpy(labels.values)\n",
    "\n",
    "dataset = TensorDataset(tensor, labeltensor)\n",
    "\n",
    "\n",
    "train_ratio = 0.6 # ratio of data to be used for training\n",
    "\n",
    "train_len = int(train_ratio * len(dataset))\n",
    "test_len = len(dataset) - train_len\n",
    "\n",
    "train_set, test_set = random_split(dataset, [train_len, test_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12a81dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "loaderVal = DataLoader(test_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fc44136",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MihaNetForSwag(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MihaNetForSwag, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(54, 256)\n",
    "        self.fc2 = nn.Linear(256, 64) \n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "class MihaNetForSwag2(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MihaNetForSwag2, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(54, 256)\n",
    "        self.fc2 = nn.Linear(256, 64) \n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "    \n",
    "class DeepDropNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DeepDropNet, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(54, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 512) \n",
    "        self.fc4 = nn.Linear(512, 256) \n",
    "        self.fc5 = nn.Linear(256, 1)\n",
    "        forget_rate = 0.15\n",
    "        self.dropout = nn.Dropout(forget_rate)\n",
    "        self.dropout2 = nn.Dropout(forget_rate)\n",
    "        self.dropout3 = nn.Dropout(forget_rate)\n",
    "        self.dropout4 = nn.Dropout(forget_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = torch.sigmoid(self.fc5(x))\n",
    "        return x\n",
    "    \n",
    "class SimpleNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(54, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c0f57f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120, Loss: 0.4717\n",
      "Epoch 2/120, Loss: 0.4707\n",
      "Epoch 3/120, Loss: 0.2524\n",
      "Epoch 4/120, Loss: 0.5984\n",
      "Epoch 5/120, Loss: 0.1608\n",
      "Epoch 6/120, Loss: 0.4070\n",
      "Epoch 7/120, Loss: 0.2039\n",
      "Epoch 8/120, Loss: 0.2944\n",
      "Epoch 9/120, Loss: 0.4486\n",
      "Epoch 10/120, Loss: 0.3698\n",
      "Epoch 11/120, Loss: 0.4246\n",
      "Epoch 12/120, Loss: 0.2377\n",
      "Epoch 13/120, Loss: 0.1453\n",
      "Epoch 14/120, Loss: 0.2825\n",
      "Epoch 15/120, Loss: 0.1614\n",
      "Epoch 16/120, Loss: 0.3573\n",
      "Epoch 17/120, Loss: 0.3195\n",
      "Epoch 18/120, Loss: 0.1024\n",
      "Epoch 19/120, Loss: 0.1776\n",
      "Epoch 20/120, Loss: 0.1322\n",
      "Epoch 21/120, Loss: 0.3271\n",
      "Epoch 22/120, Loss: 0.3598\n",
      "Epoch 23/120, Loss: 0.0930\n",
      "Epoch 24/120, Loss: 0.1124\n",
      "Epoch 25/120, Loss: 0.4011\n",
      "Epoch 26/120, Loss: 0.2347\n",
      "Epoch 27/120, Loss: 0.3127\n",
      "Epoch 28/120, Loss: 0.2103\n",
      "Epoch 29/120, Loss: 0.5104\n",
      "Epoch 30/120, Loss: 0.2060\n",
      "Epoch 31/120, Loss: 0.5615\n",
      "Epoch 32/120, Loss: 0.0632\n",
      "Epoch 33/120, Loss: 0.2713\n",
      "Epoch 34/120, Loss: 0.1599\n",
      "Epoch 35/120, Loss: 0.3690\n",
      "Epoch 36/120, Loss: 0.4139\n",
      "Epoch 37/120, Loss: 0.1012\n",
      "Epoch 38/120, Loss: 0.1026\n",
      "Epoch 39/120, Loss: 0.0842\n",
      "Epoch 40/120, Loss: 0.3465\n",
      "Epoch 41/120, Loss: 0.3701\n",
      "Epoch 42/120, Loss: 0.1284\n",
      "Epoch 43/120, Loss: 0.2163\n",
      "Epoch 44/120, Loss: 0.1723\n",
      "Epoch 45/120, Loss: 0.1108\n",
      "Epoch 46/120, Loss: 0.4093\n",
      "Epoch 47/120, Loss: 0.5805\n",
      "Epoch 48/120, Loss: 0.1115\n",
      "Epoch 49/120, Loss: 0.4322\n",
      "Epoch 50/120, Loss: 0.2508\n",
      "Epoch 51/120, Loss: 0.0936\n",
      "Epoch 52/120, Loss: 0.1022\n",
      "Epoch 53/120, Loss: 0.3898\n",
      "Epoch 54/120, Loss: 0.0835\n",
      "Epoch 55/120, Loss: 0.3161\n",
      "Epoch 56/120, Loss: 0.2835\n",
      "Epoch 57/120, Loss: 0.1815\n",
      "Epoch 58/120, Loss: 0.0548\n",
      "Epoch 59/120, Loss: 0.1476\n",
      "Epoch 60/120, Loss: 0.0592\n",
      "Epoch 61/120, Loss: 0.5138\n",
      "Epoch 62/120, Loss: 0.2618\n",
      "Epoch 63/120, Loss: 0.0593\n",
      "Epoch 64/120, Loss: 0.1925\n",
      "Epoch 65/120, Loss: 0.3554\n",
      "Epoch 66/120, Loss: 0.1498\n",
      "Epoch 67/120, Loss: 0.0318\n",
      "Epoch 68/120, Loss: 0.0689\n",
      "Epoch 69/120, Loss: 0.1350\n",
      "Epoch 70/120, Loss: 0.0365\n",
      "Epoch 71/120, Loss: 0.1107\n",
      "Epoch 72/120, Loss: 0.0381\n",
      "Epoch 73/120, Loss: 0.1872\n",
      "Epoch 74/120, Loss: 0.3128\n",
      "Epoch 75/120, Loss: 0.0678\n",
      "Epoch 76/120, Loss: 0.0940\n",
      "Epoch 77/120, Loss: 0.1268\n",
      "Epoch 78/120, Loss: 0.1508\n",
      "Epoch 79/120, Loss: 0.1076\n",
      "Epoch 80/120, Loss: 0.2111\n",
      "Epoch 81/120, Loss: 0.0727\n",
      "Epoch 82/120, Loss: 0.1209\n",
      "Epoch 83/120, Loss: 0.1895\n",
      "Epoch 84/120, Loss: 0.0607\n",
      "Epoch 85/120, Loss: 0.1330\n",
      "Epoch 86/120, Loss: 0.1195\n",
      "Epoch 87/120, Loss: 0.1210\n",
      "Epoch 88/120, Loss: 0.1835\n",
      "Epoch 89/120, Loss: 0.0643\n",
      "Epoch 90/120, Loss: 0.1112\n",
      "Epoch 91/120, Loss: 0.0723\n",
      "Epoch 92/120, Loss: 0.2365\n",
      "Epoch 93/120, Loss: 0.1101\n",
      "Epoch 94/120, Loss: 0.2690\n",
      "Epoch 95/120, Loss: 0.1721\n",
      "Epoch 96/120, Loss: 0.1277\n",
      "Epoch 97/120, Loss: 0.0994\n",
      "Epoch 98/120, Loss: 0.1777\n",
      "Epoch 99/120, Loss: 0.1646\n",
      "Epoch 100/120, Loss: 0.1649\n",
      "Epoch 101/120, Loss: 0.0320\n",
      "Epoch 102/120, Loss: 0.1711\n",
      "Epoch 103/120, Loss: 0.0850\n",
      "Epoch 104/120, Loss: 0.2255\n",
      "Epoch 105/120, Loss: 0.0612\n",
      "Epoch 106/120, Loss: 0.0979\n",
      "Epoch 107/120, Loss: 0.1160\n",
      "Epoch 108/120, Loss: 0.1463\n",
      "Epoch 109/120, Loss: 0.0818\n",
      "Epoch 110/120, Loss: 0.0961\n",
      "Epoch 111/120, Loss: 0.0757\n",
      "Epoch 112/120, Loss: 0.1927\n",
      "Epoch 113/120, Loss: 0.1247\n",
      "Epoch 114/120, Loss: 0.0369\n",
      "Epoch 115/120, Loss: 0.2108\n",
      "Epoch 116/120, Loss: 0.3741\n",
      "Epoch 117/120, Loss: 0.1470\n",
      "Epoch 118/120, Loss: 0.1783\n",
      "Epoch 119/120, Loss: 0.2313\n",
      "Epoch 120/120, Loss: 0.2190\n"
     ]
    }
   ],
   "source": [
    "# set the number of training iterations (epochs)\n",
    "num_epochs = 120\n",
    "#torch.set_grad_enabled(True) \n",
    "\n",
    "model = SimpleNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0002)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# start the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # loop over the training data in batches\n",
    "    for data, labels in loader:\n",
    "        output = model(data.type(torch.FloatTensor))\n",
    "        loss = criterion(output, labels.reshape(-1,1).type(torch.FloatTensor))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # print the loss at the end of the epoch\n",
    "    print(\"Epoch {}/{}, Loss: {:.4f}\".format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00aa9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3718\n"
     ]
    }
   ],
   "source": [
    "validations = []\n",
    "val_inputs = []\n",
    "\n",
    "\n",
    "for x, y in loaderVal:\n",
    "    for xt in x:\n",
    "        # print(xt)\n",
    "        val_inputs.append(xt.numpy())\n",
    "    for yt in y:\n",
    "        validations.append(yt)\n",
    "\n",
    "# print(val_inputs)\n",
    "        \n",
    "model.eval()\n",
    "out = model.forward(torch.from_numpy(np.array(val_inputs)).type(torch.FloatTensor))\n",
    "val_loss = criterion(out,torch.from_numpy(np.array(validations)).type(torch.FloatTensor).reshape(-1,1)) \n",
    "vl = val_loss\n",
    "\n",
    "print(\"Validation Loss: {:.4f}\".format(vl.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39b902c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ids \u001b[38;5;241m=\u001b[39m \u001b[43mdfTest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py:5685\u001b[0m, in \u001b[0;36mDataFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   5644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m   5645\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5646\u001b[0m \u001b[38;5;124;03m    Return item and drop from frame. Raise KeyError if not found.\u001b[39;00m\n\u001b[0;32m   5647\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5683\u001b[0m \u001b[38;5;124;03m    3  monkey        NaN\u001b[39;00m\n\u001b[0;32m   5684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py:923\u001b[0m, in \u001b[0;36mNDFrame.pop\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpop\u001b[39m(\u001b[38;5;28mself\u001b[39m, item: Hashable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m Any:\n\u001b[1;32m--> 923\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m[item]\n\u001b[0;32m    926\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "ids = dfTest.pop(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a102345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.get_dummies(dfTest, columns=cat_col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c39d903",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_setf = sca.transform(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cba735eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for data in test_setf:\n",
    "    final.append(model(torch.from_numpy(data).type(torch.FloatTensor)).detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69f8114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Output = pd.DataFrame({'id':ids,'Attrition':final})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d7752fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Attrition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1677</td>\n",
       "      <td>0.038483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1678</td>\n",
       "      <td>0.066631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1679</td>\n",
       "      <td>0.000514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1680</td>\n",
       "      <td>0.002333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1681</td>\n",
       "      <td>0.533811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  Attrition\n",
       "0  1677   0.038483\n",
       "1  1678   0.066631\n",
       "2  1679   0.000514\n",
       "3  1680   0.002333\n",
       "4  1681   0.533811"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Output.to_csv('Submision.csv',index=False)\n",
    "Output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f29d0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful to overwrite our original name file!\n",
    "model_name = 'simplenet.net'\n",
    "torch.save(model.state_dict(),model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
