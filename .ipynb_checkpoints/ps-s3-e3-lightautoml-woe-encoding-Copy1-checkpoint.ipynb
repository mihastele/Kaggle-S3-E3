{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32e6e769",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-01-20T11:24:47.040989Z",
     "iopub.status.busy": "2023-01-20T11:24:47.040603Z",
     "iopub.status.idle": "2023-01-20T11:26:30.406867Z",
     "shell.execute_reply": "2023-01-20T11:26:30.405969Z"
    },
    "papermill": {
     "duration": 103.377748,
     "end_time": "2023-01-20T11:26:30.410452",
     "exception": false,
     "start_time": "2023-01-20T11:24:47.032704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightautoml\r\n",
      "  Downloading LightAutoML-0.3.7.3-py3-none-any.whl (319 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.6/319.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22 in /opt/conda/lib/python3.7/site-packages (from lightautoml) (1.0.2)\r\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.7/site-packages (from lightautoml) (0.11.2)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from lightautoml) (1.0.1)\r\n",
      "Requirement already satisfied: cmaes in /opt/conda/lib/python3.7/site-packages (from lightautoml) (0.9.0)\r\n",
      "Requirement already satisfied: holidays in /opt/conda/lib/python3.7/site-packages (from lightautoml) (0.18)\r\n",
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.7/site-packages (from lightautoml) (3.0.5)\r\n",
      "Requirement already satisfied: catboost>=0.26.1 in /opt/conda/lib/python3.7/site-packages (from lightautoml) (1.1.1)\r\n",
      "Requirement already satisfied: pandas<=1.3.5 in /opt/conda/lib/python3.7/site-packages (from lightautoml) (1.3.5)\r\n",
      "Collecting poetry-core<2.0.0,>=1.0.0\r\n",
      "  Downloading poetry_core-1.4.0-py3-none-any.whl (546 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m546.4/546.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from lightautoml) (0.12.0+cpu)\r\n",
      "Collecting importlib-metadata<2.0,>=1.0\r\n",
      "  Downloading importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from lightautoml) (2.5)\r\n",
      "Collecting lightgbm<=3.2.1,>=2.3\r\n",
      "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from lightautoml) (4.64.0)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from lightautoml) (6.0)\r\n",
      "Collecting json2html\r\n",
      "  Downloading json2html-1.3.0.tar.gz (7.0 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting autowoe>=1.2\r\n",
      "  Downloading AutoWoE-1.3.2-py3-none-any.whl (215 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.7/215.7 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torch<1.9\r\n",
      "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m804.1/804.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from lightautoml) (3.1.2)\r\n",
      "Requirement already satisfied: sphinx-rtd-theme in /opt/conda/lib/python3.7/site-packages (from autowoe>=1.2->lightautoml) (0.2.4)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from autowoe>=1.2->lightautoml) (1.21.6)\r\n",
      "Collecting sphinx\r\n",
      "  Downloading sphinx-5.3.0-py3-none-any.whl (3.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from autowoe>=1.2->lightautoml) (2022.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from autowoe>=1.2->lightautoml) (3.5.3)\r\n",
      "Collecting StrEnum<0.5.0,>=0.4.7\r\n",
      "  Downloading StrEnum-0.4.9-py3-none-any.whl (7.6 kB)\r\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (from autowoe>=1.2->lightautoml) (7.2.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from autowoe>=1.2->lightautoml) (1.7.3)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from catboost>=0.26.1->lightautoml) (1.15.0)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.7/site-packages (from catboost>=0.26.1->lightautoml) (0.8.4)\r\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.7/site-packages (from catboost>=0.26.1->lightautoml) (5.11.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<2.0,>=1.0->lightautoml) (3.8.0)\r\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm<=3.2.1,>=2.3->lightautoml) (0.37.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas<=1.3.5->lightautoml) (2.8.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.22->lightautoml) (3.1.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch<1.9->lightautoml) (4.1.1)\r\n",
      "Requirement already satisfied: convertdate>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from holidays->lightautoml) (2.4.0)\r\n",
      "Requirement already satisfied: hijri-converter in /opt/conda/lib/python3.7/site-packages (from holidays->lightautoml) (2.2.4)\r\n",
      "Requirement already satisfied: PyMeeus in /opt/conda/lib/python3.7/site-packages (from holidays->lightautoml) (0.5.12)\r\n",
      "Requirement already satisfied: korean-lunar-calendar in /opt/conda/lib/python3.7/site-packages (from holidays->lightautoml) (0.3.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->lightautoml) (2.1.1)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx->lightautoml) (5.1.1)\r\n",
      "Requirement already satisfied: cliff in /opt/conda/lib/python3.7/site-packages (from optuna->lightautoml) (3.10.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from optuna->lightautoml) (22.0)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from optuna->lightautoml) (1.4.39)\r\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.7/site-packages (from optuna->lightautoml) (6.7.0)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from optuna->lightautoml) (1.9.1)\r\n",
      "Collecting torchvision\r\n",
      "  Downloading torchvision-0.14.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->lightautoml) (9.1.1)\r\n",
      "  Downloading torchvision-0.14.0-cp37-cp37m-manylinux1_x86_64.whl (24.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->lightautoml) (2.28.1)\r\n",
      "  Downloading torchvision-0.13.1-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading torchvision-0.13.0-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading torchvision-0.11.3-cp37-cp37m-manylinux1_x86_64.whl (23.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading torchvision-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.3/23.3 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading torchvision-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.3/23.3 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading torchvision-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.1/22.1 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading torchvision-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (22.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.1/22.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from alembic>=1.5.0->optuna->lightautoml) (5.10.2)\r\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.7/site-packages (from alembic>=1.5.0->optuna->lightautoml) (1.2.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (1.4.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (0.11.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (3.0.9)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->autowoe>=1.2->lightautoml) (4.33.3)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.7/site-packages (from sqlalchemy>=1.3.0->optuna->lightautoml) (1.1.2)\r\n",
      "Requirement already satisfied: stevedore>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna->lightautoml) (3.5.2)\r\n",
      "Requirement already satisfied: cmd2>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna->lightautoml) (2.4.2)\r\n",
      "Requirement already satisfied: autopage>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna->lightautoml) (0.5.1)\r\n",
      "Requirement already satisfied: PrettyTable>=0.7.2 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna->lightautoml) (3.3.0)\r\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from cliff->optuna->lightautoml) (5.11.0)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly->catboost>=0.26.1->lightautoml) (8.0.1)\r\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest->autowoe>=1.2->lightautoml) (21.4.0)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.7/site-packages (from pytest->autowoe>=1.2->lightautoml) (1.1.0)\r\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest->autowoe>=1.2->lightautoml) (2.0.1)\r\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest->autowoe>=1.2->lightautoml) (1.1.1)\r\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->autowoe>=1.2->lightautoml) (1.0.0)\r\n",
      "Collecting alabaster<0.8,>=0.7\r\n",
      "  Downloading alabaster-0.7.13-py3-none-any.whl (13 kB)\r\n",
      "Requirement already satisfied: docutils<0.20,>=0.14 in /opt/conda/lib/python3.7/site-packages (from sphinx->autowoe>=1.2->lightautoml) (0.19)\r\n",
      "Requirement already satisfied: babel>=2.9 in /opt/conda/lib/python3.7/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.10.3)\r\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0\r\n",
      "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.5/100.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting sphinxcontrib-qthelp\r\n",
      "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting imagesize>=1.3\r\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\r\n",
      "Collecting sphinx\r\n",
      "  Downloading sphinx-5.2.3-py3-none-any.whl (3.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading sphinx-5.2.2-py3-none-any.whl (3.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading sphinx-5.2.1-py3-none-any.whl (3.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading sphinx-5.2.0.post0-py3-none-any.whl (3.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading sphinx-5.2.0-py3-none-any.whl (3.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading Sphinx-5.1.1-py3-none-any.whl (3.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting sphinxcontrib-applehelp\r\n",
      "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting sphinx\r\n",
      "  Downloading Sphinx-5.1.0-py3-none-any.whl (3.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading Sphinx-5.0.2-py3-none-any.whl (3.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting docutils<0.19,>=0.14\r\n",
      "  Downloading docutils-0.18.1-py2.py3-none-any.whl (570 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.0/570.0 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting sphinx\r\n",
      "  Downloading Sphinx-5.0.1-py3-none-any.whl (3.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading Sphinx-5.0.0-py3-none-any.whl (3.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading Sphinx-4.5.0-py3-none-any.whl (3.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting docutils<0.18,>=0.14\r\n",
      "  Downloading docutils-0.17.1-py2.py3-none-any.whl (575 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.5/575.5 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting sphinx\r\n",
      "  Downloading Sphinx-4.4.0-py3-none-any.whl (3.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Downloading Sphinx-4.3.2-py3-none-any.whl (3.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from sphinx->autowoe>=1.2->lightautoml) (59.8.0)\r\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /opt/conda/lib/python3.7/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.2.0)\r\n",
      "Collecting sphinxcontrib-devhelp\r\n",
      "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/84.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: Pygments>=2.0 in /opt/conda/lib/python3.7/site-packages (from sphinx->autowoe>=1.2->lightautoml) (2.12.0)\r\n",
      "Collecting sphinxcontrib-jsmath\r\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\r\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.5\r\n",
      "  Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna->lightautoml) (0.2.5)\r\n",
      "Requirement already satisfied: pyperclip>=1.6 in /opt/conda/lib/python3.7/site-packages (from cmd2>=1.0.0->cliff->optuna->lightautoml) (1.8.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->lightautoml) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->lightautoml) (2.1.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->lightautoml) (1.26.13)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->lightautoml) (2022.12.7)\r\n",
      "Building wheels for collected packages: json2html\r\n",
      "  Building wheel for json2html (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for json2html: filename=json2html-1.3.0-py3-none-any.whl size=7609 sha256=f961a684b064f548484ea4de02f7b1bceb4c82d70052e89afce4bfbb7aa56155\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/99/37/e1839a5ad733e0d6abb7e0419fd913e8926ddf96408239ce01\r\n",
      "Successfully built json2html\r\n",
      "Installing collected packages: StrEnum, json2html, torch, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, importlib-metadata, imagesize, docutils, alabaster, torchvision, sphinx, poetry-core, lightgbm, autowoe, lightautoml\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.11.0+cpu\r\n",
      "    Uninstalling torch-1.11.0+cpu:\r\n",
      "      Successfully uninstalled torch-1.11.0+cpu\r\n",
      "  Attempting uninstall: importlib-metadata\r\n",
      "    Found existing installation: importlib-metadata 4.13.0\r\n",
      "    Uninstalling importlib-metadata-4.13.0:\r\n",
      "      Successfully uninstalled importlib-metadata-4.13.0\r\n",
      "  Attempting uninstall: docutils\r\n",
      "    Found existing installation: docutils 0.19\r\n",
      "    Uninstalling docutils-0.19:\r\n",
      "      Successfully uninstalled docutils-0.19\r\n",
      "  Attempting uninstall: torchvision\r\n",
      "    Found existing installation: torchvision 0.12.0+cpu\r\n",
      "    Uninstalling torchvision-0.12.0+cpu:\r\n",
      "      Successfully uninstalled torchvision-0.12.0+cpu\r\n",
      "  Attempting uninstall: lightgbm\r\n",
      "    Found existing installation: lightgbm 3.3.2\r\n",
      "    Uninstalling lightgbm-3.3.2:\r\n",
      "      Successfully uninstalled lightgbm-3.3.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.8.1 which is incompatible.\r\n",
      "torchaudio 0.11.0+cpu requires torch==1.11.0, but you have torch 1.8.1 which is incompatible.\r\n",
      "pytorch-lightning 1.8.6 requires torch>=1.9.0, but you have torch 1.8.1 which is incompatible.\r\n",
      "pynndescent 0.5.8 requires importlib-metadata>=4.8.1; python_version < \"3.8\", but you have importlib-metadata 1.7.0 which is incompatible.\r\n",
      "pydocstyle 6.2.2 requires importlib-metadata<5.0.0,>=2.0.0; python_version < \"3.8\", but you have importlib-metadata 1.7.0 which is incompatible.\r\n",
      "markdown 3.3.7 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 1.7.0 which is incompatible.\r\n",
      "lightning-utilities 0.5.0 requires importlib-metadata>=4.0.0; python_version < \"3.8\", but you have importlib-metadata 1.7.0 which is incompatible.\r\n",
      "keyring 23.6.0 requires importlib-metadata>=3.6; python_version < \"3.10\", but you have importlib-metadata 1.7.0 which is incompatible.\r\n",
      "ibis-framework 2.1.1 requires importlib-metadata<5,>=4; python_version < \"3.8\", but you have importlib-metadata 1.7.0 which is incompatible.\r\n",
      "gym 0.26.2 requires importlib-metadata>=4.8.0; python_version < \"3.10\", but you have importlib-metadata 1.7.0 which is incompatible.\r\n",
      "flask 2.2.2 requires importlib-metadata>=3.6.0; python_version < \"3.10\", but you have importlib-metadata 1.7.0 which is incompatible.\r\n",
      "cmudict 1.0.13 requires importlib-metadata<6.0.0,>=5.1.0, but you have importlib-metadata 1.7.0 which is incompatible.\r\n",
      "allennlp 2.10.1 requires torch<1.13.0,>=1.10.0, but you have torch 1.8.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed StrEnum-0.4.9 alabaster-0.7.13 autowoe-1.3.2 docutils-0.17.1 imagesize-1.4.1 importlib-metadata-1.7.0 json2html-1.3.0 lightautoml-0.3.7.3 lightgbm-3.2.1 poetry-core-1.4.0 sphinx-4.3.2 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 torch-1.8.1 torchvision-0.9.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2022.1)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.21.6)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv\n",
      "/kaggle/input/playground-series-s3e3/sample_submission.csv\n",
      "/kaggle/input/playground-series-s3e3/train.csv\n",
      "/kaggle/input/playground-series-s3e3/test.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip3 install -U lightautoml\n",
    "\n",
    "# QUICK WORKAROUND FOR PROBLEM WITH PANDAS\n",
    "!pip3 install -U pandas\n",
    "\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.tasks import Task\n",
    "\n",
    "import torch\n",
    "\n",
    "from category_encoders import WOEEncoder\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3c4c82",
   "metadata": {
    "papermill": {
     "duration": 0.052524,
     "end_time": "2023-01-20T11:26:30.516641",
     "exception": false,
     "start_time": "2023-01-20T11:26:30.464117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Downloading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43fce948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:30.623576Z",
     "iopub.status.busy": "2023-01-20T11:26:30.622725Z",
     "iopub.status.idle": "2023-01-20T11:26:30.682044Z",
     "shell.execute_reply": "2023-01-20T11:26:30.681368Z"
    },
    "papermill": {
     "duration": 0.115235,
     "end_time": "2023-01-20T11:26:30.684131",
     "exception": false,
     "start_time": "2023-01-20T11:26:30.568896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/playground-series-s3e3/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/playground-series-s3e3/test.csv')\n",
    "submission = pd.read_csv('/kaggle/input/playground-series-s3e3/sample_submission.csv')\n",
    "addition_data = pd.read_csv('/kaggle/input/ibm-hr-analytics-attrition-dataset/WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "\n",
    "train_df['is_generated'] = 1\n",
    "test_df['is_generated'] = 1\n",
    "addition_data['is_generated'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54edaad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:30.793623Z",
     "iopub.status.busy": "2023-01-20T11:26:30.792974Z",
     "iopub.status.idle": "2023-01-20T11:26:30.805836Z",
     "shell.execute_reply": "2023-01-20T11:26:30.804734Z"
    },
    "papermill": {
     "duration": 0.070421,
     "end_time": "2023-01-20T11:26:30.808165",
     "exception": false,
     "start_time": "2023-01-20T11:26:30.737744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop(527).drop(1398).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13fb1b0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:30.916802Z",
     "iopub.status.busy": "2023-01-20T11:26:30.916281Z",
     "iopub.status.idle": "2023-01-20T11:26:30.943812Z",
     "shell.execute_reply": "2023-01-20T11:26:30.942901Z"
    },
    "papermill": {
     "duration": 0.083879,
     "end_time": "2023-01-20T11:26:30.945782",
     "exception": false,
     "start_time": "2023-01-20T11:26:30.861903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>...</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>is_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>599</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>921</td>\n",
       "      <td>Sales</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>718</td>\n",
       "      <td>Sales</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1488</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1017</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>30</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>945</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>32</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1303</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>29</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1184</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>36</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>441</td>\n",
       "      <td>Sales</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>36</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1141</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1675 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age     BusinessTravel  DailyRate              Department  \\\n",
       "0      36  Travel_Frequently        599  Research & Development   \n",
       "1      35      Travel_Rarely        921                   Sales   \n",
       "2      32      Travel_Rarely        718                   Sales   \n",
       "3      38      Travel_Rarely       1488  Research & Development   \n",
       "4      50      Travel_Rarely       1017  Research & Development   \n",
       "...   ...                ...        ...                     ...   \n",
       "1670   30      Travel_Rarely        945                   Sales   \n",
       "1671   32      Travel_Rarely       1303  Research & Development   \n",
       "1672   29  Travel_Frequently       1184         Human Resources   \n",
       "1673   36      Travel_Rarely        441                   Sales   \n",
       "1674   36      Travel_Rarely       1141  Research & Development   \n",
       "\n",
       "      DistanceFromHome  Education   EducationField  EmployeeCount  \\\n",
       "0                   24          3          Medical              1   \n",
       "1                    8          3            Other              1   \n",
       "2                   26          3        Marketing              1   \n",
       "3                    2          3          Medical              1   \n",
       "4                    5          4          Medical              1   \n",
       "...                ...        ...              ...            ...   \n",
       "1670                 1          3    Life Sciences              1   \n",
       "1671                 2          3    Life Sciences              1   \n",
       "1672                24          3  Human Resources              1   \n",
       "1673                 9          2        Marketing              1   \n",
       "1674                20          3    Life Sciences              1   \n",
       "\n",
       "      EnvironmentSatisfaction  Gender  ...  StockOptionLevel  \\\n",
       "0                           4    Male  ...                 1   \n",
       "1                           1    Male  ...                 1   \n",
       "2                           3    Male  ...                 2   \n",
       "3                           3  Female  ...                 0   \n",
       "4                           2  Female  ...                 0   \n",
       "...                       ...     ...  ...               ...   \n",
       "1670                        4  Female  ...                 0   \n",
       "1671                        1    Male  ...                 1   \n",
       "1672                        2    Male  ...                 0   \n",
       "1673                        2    Male  ...                 2   \n",
       "1674                        3  Female  ...                 0   \n",
       "\n",
       "      TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                    10                      2               3   \n",
       "1                     4                      3               3   \n",
       "2                     4                      3               3   \n",
       "3                    15                      1               1   \n",
       "4                    31                      0               3   \n",
       "...                 ...                    ...             ...   \n",
       "1670                 10                      2               4   \n",
       "1671                 10                      3               4   \n",
       "1672                  1                      2               3   \n",
       "1673                 10                      3               2   \n",
       "1674                 10                      3               2   \n",
       "\n",
       "      YearsAtCompany YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0                 10                  0                        7   \n",
       "1                  4                  2                        0   \n",
       "2                  3                  2                        1   \n",
       "3                  6                  0                        0   \n",
       "4                 31                 14                        4   \n",
       "...              ...                ...                      ...   \n",
       "1670              10                  0                        0   \n",
       "1671               4                  2                        1   \n",
       "1672               1                  0                        0   \n",
       "1673              10                  3                        0   \n",
       "1674               8                  2                        7   \n",
       "\n",
       "      YearsWithCurrManager  Attrition is_generated  \n",
       "0                        8          0            1  \n",
       "1                        3          0            1  \n",
       "2                        2          0            1  \n",
       "3                        2          0            1  \n",
       "4                       10          1            1  \n",
       "...                    ...        ...          ...  \n",
       "1670                     8          0            1  \n",
       "1671                     3          0            1  \n",
       "1672                     0          1            1  \n",
       "1673                     8          0            1  \n",
       "1674                     3          0            1  \n",
       "\n",
       "[1675 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.drop('id', axis=1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6cc19d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:31.054130Z",
     "iopub.status.busy": "2023-01-20T11:26:31.053639Z",
     "iopub.status.idle": "2023-01-20T11:26:31.246234Z",
     "shell.execute_reply": "2023-01-20T11:26:31.245642Z"
    },
    "papermill": {
     "duration": 0.248925,
     "end_time": "2023-01-20T11:26:31.248332",
     "exception": false,
     "start_time": "2023-01-20T11:26:30.999407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.Attrition.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe26d137",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:31.358036Z",
     "iopub.status.busy": "2023-01-20T11:26:31.357162Z",
     "iopub.status.idle": "2023-01-20T11:26:31.365303Z",
     "shell.execute_reply": "2023-01-20T11:26:31.364734Z"
    },
    "papermill": {
     "duration": 0.064846,
     "end_time": "2023-01-20T11:26:31.366873",
     "exception": false,
     "start_time": "2023-01-20T11:26:31.302027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         False\n",
       "BusinessTravel              False\n",
       "DailyRate                   False\n",
       "Department                  False\n",
       "DistanceFromHome            False\n",
       "Education                   False\n",
       "EducationField              False\n",
       "EmployeeCount               False\n",
       "EnvironmentSatisfaction     False\n",
       "Gender                      False\n",
       "HourlyRate                  False\n",
       "JobInvolvement              False\n",
       "JobLevel                    False\n",
       "JobRole                     False\n",
       "JobSatisfaction             False\n",
       "MaritalStatus               False\n",
       "MonthlyIncome               False\n",
       "MonthlyRate                 False\n",
       "NumCompaniesWorked          False\n",
       "Over18                      False\n",
       "OverTime                    False\n",
       "PercentSalaryHike           False\n",
       "PerformanceRating           False\n",
       "RelationshipSatisfaction    False\n",
       "StandardHours               False\n",
       "StockOptionLevel            False\n",
       "TotalWorkingYears           False\n",
       "TrainingTimesLastYear       False\n",
       "WorkLifeBalance             False\n",
       "YearsAtCompany              False\n",
       "YearsInCurrentRole          False\n",
       "YearsSinceLastPromotion     False\n",
       "YearsWithCurrManager        False\n",
       "Attrition                   False\n",
       "is_generated                False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00b85464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:31.475373Z",
     "iopub.status.busy": "2023-01-20T11:26:31.474569Z",
     "iopub.status.idle": "2023-01-20T11:26:31.496948Z",
     "shell.execute_reply": "2023-01-20T11:26:31.495728Z"
    },
    "papermill": {
     "duration": 0.078076,
     "end_time": "2023-01-20T11:26:31.498465",
     "exception": false,
     "start_time": "2023-01-20T11:26:31.420389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EmployeeNumber</th>\n",
       "      <th>...</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>is_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>884</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2061</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>613</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2062</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>155</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2064</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1023</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2065</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>628</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2068</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0      41          1      Travel_Rarely       1102                   Sales   \n",
       "1      49          0  Travel_Frequently        279  Research & Development   \n",
       "2      37          1      Travel_Rarely       1373  Research & Development   \n",
       "3      33          0  Travel_Frequently       1392  Research & Development   \n",
       "4      27          0      Travel_Rarely        591  Research & Development   \n",
       "...   ...        ...                ...        ...                     ...   \n",
       "1465   36          0  Travel_Frequently        884  Research & Development   \n",
       "1466   39          0      Travel_Rarely        613  Research & Development   \n",
       "1467   27          0      Travel_Rarely        155  Research & Development   \n",
       "1468   49          0  Travel_Frequently       1023                   Sales   \n",
       "1469   34          0      Travel_Rarely        628  Research & Development   \n",
       "\n",
       "      DistanceFromHome  Education EducationField  EmployeeCount  \\\n",
       "0                    1          2  Life Sciences              1   \n",
       "1                    8          1  Life Sciences              1   \n",
       "2                    2          2          Other              1   \n",
       "3                    3          4  Life Sciences              1   \n",
       "4                    2          1        Medical              1   \n",
       "...                ...        ...            ...            ...   \n",
       "1465                23          2        Medical              1   \n",
       "1466                 6          1        Medical              1   \n",
       "1467                 4          3  Life Sciences              1   \n",
       "1468                 2          3        Medical              1   \n",
       "1469                 8          3        Medical              1   \n",
       "\n",
       "      EmployeeNumber  ...  StandardHours StockOptionLevel  TotalWorkingYears  \\\n",
       "0                  1  ...             80                0                  8   \n",
       "1                  2  ...             80                1                 10   \n",
       "2                  4  ...             80                0                  7   \n",
       "3                  5  ...             80                0                  8   \n",
       "4                  7  ...             80                1                  6   \n",
       "...              ...  ...            ...              ...                ...   \n",
       "1465            2061  ...             80                1                 17   \n",
       "1466            2062  ...             80                1                  9   \n",
       "1467            2064  ...             80                1                  6   \n",
       "1468            2065  ...             80                0                 17   \n",
       "1469            2068  ...             80                0                  6   \n",
       "\n",
       "      TrainingTimesLastYear  WorkLifeBalance YearsAtCompany  \\\n",
       "0                         0                1              6   \n",
       "1                         3                3             10   \n",
       "2                         3                3              0   \n",
       "3                         3                3              8   \n",
       "4                         3                3              2   \n",
       "...                     ...              ...            ...   \n",
       "1465                      3                3              5   \n",
       "1466                      5                3              7   \n",
       "1467                      0                3              6   \n",
       "1468                      3                2              9   \n",
       "1469                      3                4              4   \n",
       "\n",
       "      YearsInCurrentRole YearsSinceLastPromotion  YearsWithCurrManager  \\\n",
       "0                      4                       0                     5   \n",
       "1                      7                       1                     7   \n",
       "2                      0                       0                     0   \n",
       "3                      7                       3                     0   \n",
       "4                      2                       2                     2   \n",
       "...                  ...                     ...                   ...   \n",
       "1465                   2                       0                     3   \n",
       "1466                   7                       1                     7   \n",
       "1467                   2                       0                     3   \n",
       "1468                   6                       0                     8   \n",
       "1469                   3                       1                     2   \n",
       "\n",
       "      is_generated  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "1465             0  \n",
       "1466             0  \n",
       "1467             0  \n",
       "1468             0  \n",
       "1469             0  \n",
       "\n",
       "[1470 rows x 36 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addition_data['Attrition'] = (addition_data['Attrition'] == 'Yes').astype(int)\n",
    "# addition_data = addition_data[addition_data.Attrition == 1]\n",
    "addition_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2423ceb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:31.607337Z",
     "iopub.status.busy": "2023-01-20T11:26:31.606643Z",
     "iopub.status.idle": "2023-01-20T11:26:31.756798Z",
     "shell.execute_reply": "2023-01-20T11:26:31.756146Z"
    },
    "papermill": {
     "duration": 0.206133,
     "end_time": "2023-01-20T11:26:31.758509",
     "exception": false,
     "start_time": "2023-01-20T11:26:31.552376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "addition_data.Attrition.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb31fb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:31.882213Z",
     "iopub.status.busy": "2023-01-20T11:26:31.881891Z",
     "iopub.status.idle": "2023-01-20T11:26:31.891085Z",
     "shell.execute_reply": "2023-01-20T11:26:31.890238Z"
    },
    "papermill": {
     "duration": 0.075853,
     "end_time": "2023-01-20T11:26:31.892933",
     "exception": false,
     "start_time": "2023-01-20T11:26:31.817080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         False\n",
       "Attrition                   False\n",
       "BusinessTravel              False\n",
       "DailyRate                   False\n",
       "Department                  False\n",
       "DistanceFromHome            False\n",
       "Education                   False\n",
       "EducationField              False\n",
       "EmployeeCount               False\n",
       "EmployeeNumber              False\n",
       "EnvironmentSatisfaction     False\n",
       "Gender                      False\n",
       "HourlyRate                  False\n",
       "JobInvolvement              False\n",
       "JobLevel                    False\n",
       "JobRole                     False\n",
       "JobSatisfaction             False\n",
       "MaritalStatus               False\n",
       "MonthlyIncome               False\n",
       "MonthlyRate                 False\n",
       "NumCompaniesWorked          False\n",
       "Over18                      False\n",
       "OverTime                    False\n",
       "PercentSalaryHike           False\n",
       "PerformanceRating           False\n",
       "RelationshipSatisfaction    False\n",
       "StandardHours               False\n",
       "StockOptionLevel            False\n",
       "TotalWorkingYears           False\n",
       "TrainingTimesLastYear       False\n",
       "WorkLifeBalance             False\n",
       "YearsAtCompany              False\n",
       "YearsInCurrentRole          False\n",
       "YearsSinceLastPromotion     False\n",
       "YearsWithCurrManager        False\n",
       "is_generated                False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addition_data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ae685c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:32.007112Z",
     "iopub.status.busy": "2023-01-20T11:26:32.006221Z",
     "iopub.status.idle": "2023-01-20T11:26:32.034876Z",
     "shell.execute_reply": "2023-01-20T11:26:32.034066Z"
    },
    "papermill": {
     "duration": 0.08555,
     "end_time": "2023-01-20T11:26:32.036827",
     "exception": false,
     "start_time": "2023-01-20T11:26:31.951277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>...</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>is_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>599</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>921</td>\n",
       "      <td>Sales</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>718</td>\n",
       "      <td>Sales</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1488</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1017</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>36</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>884</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>39</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>613</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142</th>\n",
       "      <td>27</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>155</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143</th>\n",
       "      <td>49</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1023</td>\n",
       "      <td>Sales</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>34</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>628</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3145 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age     BusinessTravel  DailyRate              Department  \\\n",
       "0      36  Travel_Frequently        599  Research & Development   \n",
       "1      35      Travel_Rarely        921                   Sales   \n",
       "2      32      Travel_Rarely        718                   Sales   \n",
       "3      38      Travel_Rarely       1488  Research & Development   \n",
       "4      50      Travel_Rarely       1017  Research & Development   \n",
       "...   ...                ...        ...                     ...   \n",
       "3140   36  Travel_Frequently        884  Research & Development   \n",
       "3141   39      Travel_Rarely        613  Research & Development   \n",
       "3142   27      Travel_Rarely        155  Research & Development   \n",
       "3143   49  Travel_Frequently       1023                   Sales   \n",
       "3144   34      Travel_Rarely        628  Research & Development   \n",
       "\n",
       "      DistanceFromHome  Education EducationField  EmployeeCount  \\\n",
       "0                   24          3        Medical              1   \n",
       "1                    8          3          Other              1   \n",
       "2                   26          3      Marketing              1   \n",
       "3                    2          3        Medical              1   \n",
       "4                    5          4        Medical              1   \n",
       "...                ...        ...            ...            ...   \n",
       "3140                23          2        Medical              1   \n",
       "3141                 6          1        Medical              1   \n",
       "3142                 4          3  Life Sciences              1   \n",
       "3143                 2          3        Medical              1   \n",
       "3144                 8          3        Medical              1   \n",
       "\n",
       "      EnvironmentSatisfaction  Gender  ...  StockOptionLevel  \\\n",
       "0                           4    Male  ...                 1   \n",
       "1                           1    Male  ...                 1   \n",
       "2                           3    Male  ...                 2   \n",
       "3                           3  Female  ...                 0   \n",
       "4                           2  Female  ...                 0   \n",
       "...                       ...     ...  ...               ...   \n",
       "3140                        3    Male  ...                 1   \n",
       "3141                        4    Male  ...                 1   \n",
       "3142                        2    Male  ...                 1   \n",
       "3143                        4    Male  ...                 0   \n",
       "3144                        2    Male  ...                 0   \n",
       "\n",
       "      TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                    10                      2               3   \n",
       "1                     4                      3               3   \n",
       "2                     4                      3               3   \n",
       "3                    15                      1               1   \n",
       "4                    31                      0               3   \n",
       "...                 ...                    ...             ...   \n",
       "3140                 17                      3               3   \n",
       "3141                  9                      5               3   \n",
       "3142                  6                      0               3   \n",
       "3143                 17                      3               2   \n",
       "3144                  6                      3               4   \n",
       "\n",
       "      YearsAtCompany YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0                 10                  0                        7   \n",
       "1                  4                  2                        0   \n",
       "2                  3                  2                        1   \n",
       "3                  6                  0                        0   \n",
       "4                 31                 14                        4   \n",
       "...              ...                ...                      ...   \n",
       "3140               5                  2                        0   \n",
       "3141               7                  7                        1   \n",
       "3142               6                  2                        0   \n",
       "3143               9                  6                        0   \n",
       "3144               4                  3                        1   \n",
       "\n",
       "      YearsWithCurrManager  Attrition is_generated  \n",
       "0                        8          0            1  \n",
       "1                        3          0            1  \n",
       "2                        2          0            1  \n",
       "3                        2          0            1  \n",
       "4                       10          1            1  \n",
       "...                    ...        ...          ...  \n",
       "3140                     3          0            0  \n",
       "3141                     7          0            0  \n",
       "3142                     3          0            0  \n",
       "3143                     8          0            0  \n",
       "3144                     2          0            0  \n",
       "\n",
       "[3145 rows x 35 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_df, addition_data],axis=0, ignore_index=True)\n",
    "train_df = train_df.drop('EmployeeNumber', axis=1)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "997cb0cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:32.147845Z",
     "iopub.status.busy": "2023-01-20T11:26:32.147281Z",
     "iopub.status.idle": "2023-01-20T11:26:32.155461Z",
     "shell.execute_reply": "2023-01-20T11:26:32.154868Z"
    },
    "papermill": {
     "duration": 0.06552,
     "end_time": "2023-01-20T11:26:32.157090",
     "exception": false,
     "start_time": "2023-01-20T11:26:32.091570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         False\n",
       "BusinessTravel              False\n",
       "DailyRate                   False\n",
       "Department                  False\n",
       "DistanceFromHome            False\n",
       "Education                   False\n",
       "EducationField              False\n",
       "EmployeeCount               False\n",
       "EnvironmentSatisfaction     False\n",
       "Gender                      False\n",
       "HourlyRate                  False\n",
       "JobInvolvement              False\n",
       "JobLevel                    False\n",
       "JobRole                     False\n",
       "JobSatisfaction             False\n",
       "MaritalStatus               False\n",
       "MonthlyIncome               False\n",
       "MonthlyRate                 False\n",
       "NumCompaniesWorked          False\n",
       "Over18                      False\n",
       "OverTime                    False\n",
       "PercentSalaryHike           False\n",
       "PerformanceRating           False\n",
       "RelationshipSatisfaction    False\n",
       "StandardHours               False\n",
       "StockOptionLevel            False\n",
       "TotalWorkingYears           False\n",
       "TrainingTimesLastYear       False\n",
       "WorkLifeBalance             False\n",
       "YearsAtCompany              False\n",
       "YearsInCurrentRole          False\n",
       "YearsSinceLastPromotion     False\n",
       "YearsWithCurrManager        False\n",
       "Attrition                   False\n",
       "is_generated                False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69d1c000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:32.267464Z",
     "iopub.status.busy": "2023-01-20T11:26:32.266934Z",
     "iopub.status.idle": "2023-01-20T11:26:32.272964Z",
     "shell.execute_reply": "2023-01-20T11:26:32.272316Z"
    },
    "papermill": {
     "duration": 0.063449,
     "end_time": "2023-01-20T11:26:32.274571",
     "exception": false,
     "start_time": "2023-01-20T11:26:32.211122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_young(x):\n",
    "    if x <=25:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def young_and_low_daily_rate(x):\n",
    "    if x['Age'] <= 25 & x['DailyRate'] < 500:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def overtime_satisfaction(x):\n",
    "        if x['OverTime'] == 'Yes':\n",
    "            return (x['MonthlyIncome'] * (x['StockOptionLevel'] + 0.05) * x['JobSatisfaction'])/x['Age']\n",
    "        else:\n",
    "            return (x['MonthlyIncome'] * (x['StockOptionLevel'] + 1.05) * x['JobSatisfaction'])/x['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9348fdd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:32.385803Z",
     "iopub.status.busy": "2023-01-20T11:26:32.385344Z",
     "iopub.status.idle": "2023-01-20T11:26:32.801401Z",
     "shell.execute_reply": "2023-01-20T11:26:32.800824Z"
    },
    "papermill": {
     "duration": 0.473919,
     "end_time": "2023-01-20T11:26:32.802981",
     "exception": false,
     "start_time": "2023-01-20T11:26:32.329062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>...</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>is_generated</th>\n",
       "      <th>id</th>\n",
       "      <th>is_young</th>\n",
       "      <th>young_and_underpaid</th>\n",
       "      <th>worklife_stock</th>\n",
       "      <th>income_satisfaction</th>\n",
       "      <th>income_level_environ_job_sat</th>\n",
       "      <th>overtime_stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>599</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10384</td>\n",
       "      <td>41536.0</td>\n",
       "      <td>302.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>921</td>\n",
       "      <td>Sales</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2899</td>\n",
       "      <td>2899.0</td>\n",
       "      <td>169.798571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>718</td>\n",
       "      <td>Sales</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18508</td>\n",
       "      <td>27762.0</td>\n",
       "      <td>1764.043750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1488</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Medical</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5347</td>\n",
       "      <td>8020.5</td>\n",
       "      <td>147.746053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1017</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Medical</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19033</td>\n",
       "      <td>7613.2</td>\n",
       "      <td>19.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>31</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>755</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2791.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18712</td>\n",
       "      <td>56136.0</td>\n",
       "      <td>1237.406452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>40</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>654</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>Medical</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2792.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24880</td>\n",
       "      <td>37320.0</td>\n",
       "      <td>1275.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>42</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>884</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Medical</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>65</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5238</td>\n",
       "      <td>5238.0</td>\n",
       "      <td>255.664286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>25</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1469</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Technical Degree</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2794.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19196</td>\n",
       "      <td>28794.0</td>\n",
       "      <td>1574.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>42</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1234</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6824</td>\n",
       "      <td>5118.0</td>\n",
       "      <td>333.076190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4264 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age     BusinessTravel  DailyRate              Department  \\\n",
       "0      36  Travel_Frequently        599  Research & Development   \n",
       "1      35      Travel_Rarely        921                   Sales   \n",
       "2      32      Travel_Rarely        718                   Sales   \n",
       "3      38      Travel_Rarely       1488  Research & Development   \n",
       "4      50      Travel_Rarely       1017  Research & Development   \n",
       "...   ...                ...        ...                     ...   \n",
       "1114   31      Travel_Rarely        755                   Sales   \n",
       "1115   40      Travel_Rarely        654  Research & Development   \n",
       "1116   42  Travel_Frequently        884  Research & Development   \n",
       "1117   25  Travel_Frequently       1469                   Sales   \n",
       "1118   42      Travel_Rarely       1234  Research & Development   \n",
       "\n",
       "      DistanceFromHome  Education    EducationField  EnvironmentSatisfaction  \\\n",
       "0                   24          3           Medical                        4   \n",
       "1                    8          3             Other                        1   \n",
       "2                   26          3         Marketing                        3   \n",
       "3                    2          3           Medical                        3   \n",
       "4                    5          4           Medical                        2   \n",
       "...                ...        ...               ...                      ...   \n",
       "1114                 1          1     Life Sciences                        3   \n",
       "1115                26          5           Medical                        3   \n",
       "1116                 1          4           Medical                        2   \n",
       "1117                 1          2  Technical Degree                        3   \n",
       "1118                 2          4     Life Sciences                        3   \n",
       "\n",
       "      Gender  HourlyRate  ...  YearsWithCurrManager  Attrition is_generated  \\\n",
       "0       Male          42  ...                     8        0.0            1   \n",
       "1       Male          46  ...                     3        0.0            1   \n",
       "2       Male          80  ...                     2        0.0            1   \n",
       "3     Female          40  ...                     2        0.0            1   \n",
       "4     Female          37  ...                    10        1.0            1   \n",
       "...      ...         ...  ...                   ...        ...          ...   \n",
       "1114    Male          81  ...                     0        NaN            1   \n",
       "1115    Male          96  ...                     8        NaN            1   \n",
       "1116  Female          65  ...                     2        NaN            1   \n",
       "1117    Male          68  ...                     3        NaN            1   \n",
       "1118  Female          95  ...                     9        NaN            1   \n",
       "\n",
       "          id is_young  young_and_underpaid  worklife_stock  \\\n",
       "0        NaN        0                    0               4   \n",
       "1        NaN        0                    0               4   \n",
       "2        NaN        0                    0               5   \n",
       "3        NaN        0                    0               1   \n",
       "4        NaN        0                    0               3   \n",
       "...      ...      ...                  ...             ...   \n",
       "1114  2791.0        0                    0               4   \n",
       "1115  2792.0        0                    0               4   \n",
       "1116  2793.0        0                    0               3   \n",
       "1117  2794.0        1                    1               4   \n",
       "1118  2795.0        0                    0               4   \n",
       "\n",
       "      income_satisfaction income_level_environ_job_sat  overtime_stock  \n",
       "0                   10384                      41536.0      302.866667  \n",
       "1                    2899                       2899.0      169.798571  \n",
       "2                   18508                      27762.0     1764.043750  \n",
       "3                    5347                       8020.5      147.746053  \n",
       "4                   19033                       7613.2       19.033000  \n",
       "...                   ...                          ...             ...  \n",
       "1114                18712                      56136.0     1237.406452  \n",
       "1115                24880                      37320.0     1275.100000  \n",
       "1116                 5238                       5238.0      255.664286  \n",
       "1117                19196                      28794.0     1574.072000  \n",
       "1118                 6824                       5118.0      333.076190  \n",
       "\n",
       "[4264 rows x 39 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([train_df, test_df], axis=0)\n",
    "df = df.drop([\"EmployeeCount\", \"Over18\", \"StandardHours\"], axis=1)\n",
    "\n",
    "df['is_young'] = df['Age'].apply(lambda x: is_young(x))\n",
    "df['young_and_underpaid'] = df.apply(lambda x: young_and_low_daily_rate(x), axis = 1)\n",
    "df['worklife_stock'] = df.apply(lambda x: x['WorkLifeBalance'] + x['StockOptionLevel'], axis = 1)\n",
    "\n",
    "df['income_satisfaction'] = df.apply(lambda x: x['JobSatisfaction'] * x['MonthlyIncome'], axis = 1)\n",
    "df['income_level_environ_job_sat'] = df.apply(lambda x: x['EnvironmentSatisfaction']*x['JobSatisfaction'] * (x['MonthlyIncome']/x['JobLevel']), axis = 1)\n",
    "df['overtime_stock'] = df.apply(lambda x: overtime_satisfaction(x), axis = 1)\n",
    "\n",
    "# df = pd.get_dummies(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdb6caa1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:32.915890Z",
     "iopub.status.busy": "2023-01-20T11:26:32.915409Z",
     "iopub.status.idle": "2023-01-20T11:26:32.920697Z",
     "shell.execute_reply": "2023-01-20T11:26:32.920137Z"
    },
    "papermill": {
     "duration": 0.063681,
     "end_time": "2023-01-20T11:26:32.922186",
     "exception": false,
     "start_time": "2023-01-20T11:26:32.858505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = ['Age', 'BusinessTravel', 'DailyRate', 'Department', 'DistanceFromHome',\n",
    "       'Education', 'EducationField', 'EnvironmentSatisfaction', 'Gender',\n",
    "       'HourlyRate', 'JobInvolvement', 'JobLevel', 'JobRole',\n",
    "       'JobSatisfaction', 'MaritalStatus', 'MonthlyIncome', 'MonthlyRate',\n",
    "       'NumCompaniesWorked', 'OverTime', 'PercentSalaryHike',\n",
    "       'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel',\n",
    "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "       'YearsWithCurrManager', 'is_generated', 'id', 'is_young',\n",
    "       'young_and_underpaid', 'worklife_stock', 'income_satisfaction',\n",
    "        'income_level_environ_job_sat', 'overtime_stock']\n",
    "cat_features = ['BusinessTravel', 'Department','Education', 'EducationField', 'EnvironmentSatisfaction', 'Gender',\n",
    "               'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus','NumCompaniesWorked', 'OverTime', \n",
    "               'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', \n",
    "                'WorkLifeBalance', 'YearsAtCompany','is_young', 'young_and_underpaid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef662d4",
   "metadata": {
    "papermill": {
     "duration": 0.053853,
     "end_time": "2023-01-20T11:26:33.032307",
     "exception": false,
     "start_time": "2023-01-20T11:26:32.978454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Woe encoder from @faelk8 notebook https://www.kaggle.com/code/faelk8/catboost/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8518e530",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:33.142731Z",
     "iopub.status.busy": "2023-01-20T11:26:33.142149Z",
     "iopub.status.idle": "2023-01-20T11:26:33.518358Z",
     "shell.execute_reply": "2023-01-20T11:26:33.517674Z"
    },
    "papermill": {
     "duration": 0.434255,
     "end_time": "2023-01-20T11:26:33.520660",
     "exception": false,
     "start_time": "2023-01-20T11:26:33.086405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "woe = WOEEncoder(drop_invariant=True, randomized = True)\n",
    "for col in cat_features:\n",
    "    df[col] = df[col].astype(str)\n",
    "woe.fit(df[features][:-len(test_df)], df['Attrition'][:-len(test_df)], cols = cat_features)\n",
    "X = woe.transform(df[features])\n",
    "X['Attrition'] = df['Attrition']\n",
    "df = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b936ef07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:33.640132Z",
     "iopub.status.busy": "2023-01-20T11:26:33.639451Z",
     "iopub.status.idle": "2023-01-20T11:26:33.655379Z",
     "shell.execute_reply": "2023-01-20T11:26:33.654740Z"
    },
    "papermill": {
     "duration": 0.077966,
     "end_time": "2023-01-20T11:26:33.658019",
     "exception": false,
     "start_time": "2023-01-20T11:26:33.580053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "y = df['Attrition']\n",
    "df = df.drop(['id', 'Attrition'], axis=1)\n",
    "\n",
    "df[df.columns] = scaler.fit_transform(df[df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7eae181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:33.787770Z",
     "iopub.status.busy": "2023-01-20T11:26:33.787131Z",
     "iopub.status.idle": "2023-01-20T11:26:33.796376Z",
     "shell.execute_reply": "2023-01-20T11:26:33.795491Z"
    },
    "papermill": {
     "duration": 0.070234,
     "end_time": "2023-01-20T11:26:33.798354",
     "exception": false,
     "start_time": "2023-01-20T11:26:33.728120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_df = df.iloc[:-len(test_df),:]\n",
    "train_df['Attrition'] = y[:-len(test_df)]\n",
    "test_df = df.iloc[-len(test_df):,:].reset_index(drop=True)\n",
    "\n",
    "X = train_df.drop('Attrition', axis=1)\n",
    "y = train_df.Attrition\n",
    "X_test = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ba2033",
   "metadata": {
    "papermill": {
     "duration": 0.054764,
     "end_time": "2023-01-20T11:26:33.908594",
     "exception": false,
     "start_time": "2023-01-20T11:26:33.853830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**The model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5458abb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:34.019572Z",
     "iopub.status.busy": "2023-01-20T11:26:34.019197Z",
     "iopub.status.idle": "2023-01-20T11:26:34.023084Z",
     "shell.execute_reply": "2023-01-20T11:26:34.022287Z"
    },
    "papermill": {
     "duration": 0.061505,
     "end_time": "2023-01-20T11:26:34.024647",
     "exception": false,
     "start_time": "2023-01-20T11:26:33.963142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3ab83b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:34.138703Z",
     "iopub.status.busy": "2023-01-20T11:26:34.138373Z",
     "iopub.status.idle": "2023-01-20T11:26:34.206398Z",
     "shell.execute_reply": "2023-01-20T11:26:34.205729Z"
    },
    "papermill": {
     "duration": 0.12721,
     "end_time": "2023-01-20T11:26:34.208383",
     "exception": false,
     "start_time": "2023-01-20T11:26:34.081173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "task = Task('binary', metric = 'auc')\n",
    "\n",
    "N_THREADS = 4\n",
    "N_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "TIMEOUT = 60 * 60\n",
    "TARGET_NAME = 'Attrition'\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)\n",
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "torch.set_num_threads(N_THREADS)\n",
    "# TabularUtilizedAutoML\n",
    "# TabularAutoML\n",
    "automl = TabularUtilizedAutoML(\n",
    "    task = task, \n",
    "    timeout = TIMEOUT,\n",
    "    cpu_limit = N_THREADS,\n",
    "    general_params = {'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},\n",
    "#     reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE}\n",
    "#     general_params = {\"use_algos\": [all_models]},\n",
    "    reader_params = {'n_jobs': N_THREADS}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6cacefa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:34.321783Z",
     "iopub.status.busy": "2023-01-20T11:26:34.321047Z",
     "iopub.status.idle": "2023-01-20T11:26:34.324656Z",
     "shell.execute_reply": "2023-01-20T11:26:34.324044Z"
    },
    "papermill": {
     "duration": 0.061769,
     "end_time": "2023-01-20T11:26:34.326171",
     "exception": false,
     "start_time": "2023-01-20T11:26:34.264402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "roles = {\n",
    "    'target': TARGET_NAME\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59b4f5a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T11:26:34.442388Z",
     "iopub.status.busy": "2023-01-20T11:26:34.441889Z",
     "iopub.status.idle": "2023-01-20T12:23:47.086974Z",
     "shell.execute_reply": "2023-01-20T12:23:47.085864Z"
    },
    "papermill": {
     "duration": 3432.706942,
     "end_time": "2023-01-20T12:23:47.090094",
     "exception": false,
     "start_time": "2023-01-20T11:26:34.383152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:26:34] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[11:26:34] - time: 3600.00 seconds\n",
      "[11:26:34] - CPU: 4 cores\n",
      "[11:26:34] - memory: 16 GB\n",
      "\n",
      "[11:26:34] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[11:26:34] ==================================================\n",
      "[11:26:34] Start 0 automl preset configuration:\n",
      "[11:26:34] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:26:34] Stdout logging level is INFO.\n",
      "[11:26:34] Task: binary\n",
      "\n",
      "[11:26:34] Start automl preset with listed constraints:\n",
      "[11:26:34] - time: 3600.00 seconds\n",
      "[11:26:34] - CPU: 4 cores\n",
      "[11:26:34] - memory: 16 GB\n",
      "\n",
      "[11:26:34] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[11:26:37] Layer \u001b[1m1\u001b[0m train process start. Time left 3597.25 secs\n",
      "[11:26:37] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:26:38] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8701558903359483\u001b[0m\n",
      "[11:26:38] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:26:38] Time left 3596.44 secs\n",
      "\n",
      "[11:26:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:26:41] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8495600796352192\u001b[0m\n",
      "[11:26:41] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:26:41] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:26:41] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[11:29:20] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:29:20] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:29:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8471880925742525\u001b[0m\n",
      "[11:29:22] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:29:22] Time left 3432.36 secs\n",
      "\n",
      "[11:29:22] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:29:22] Blending: optimization starts with equal weights and score \u001b[1m0.8634539917322688\u001b[0m\n",
      "[11:29:22] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8706383999945918\u001b[0m, weights = \u001b[1m[0.8583278  0.         0.14167216]\u001b[0m\n",
      "[11:29:22] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.870665440816092\u001b[0m, weights = \u001b[1m[0.86962485 0.         0.13037518]\u001b[0m\n",
      "[11:29:22] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.870665440816092\u001b[0m, weights = \u001b[1m[0.86962485 0.         0.13037518]\u001b[0m\n",
      "[11:29:22] Blending: no score update. Terminated\n",
      "\n",
      "[11:29:22] \u001b[1mAutoml preset training completed in 167.77 seconds\u001b[0m\n",
      "\n",
      "[11:29:22] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.86962 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.13038 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[11:29:22] ==================================================\n",
      "[11:29:22] Start 1 automl preset configuration:\n",
      "[11:29:22] \u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:29:22] Stdout logging level is INFO.\n",
      "[11:29:22] Task: binary\n",
      "\n",
      "[11:29:22] Start automl preset with listed constraints:\n",
      "[11:29:22] - time: 3432.21 seconds\n",
      "[11:29:22] - CPU: 4 cores\n",
      "[11:29:22] - memory: 16 GB\n",
      "\n",
      "[11:29:22] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[11:29:22] Layer \u001b[1m1\u001b[0m train process start. Time left 3431.92 secs\n",
      "[11:29:22] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:29:23] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8754381458108697\u001b[0m\n",
      "[11:29:23] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:29:23] Time left 3431.10 secs\n",
      "\n",
      "[11:29:24] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:29:24] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:29:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8548820513167189\u001b[0m\n",
      "[11:29:29] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:29:29] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:32:52] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:32:52] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:32:56] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8306137590459997\u001b[0m\n",
      "[11:32:56] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:32:56] Time left 3218.41 secs\n",
      "\n",
      "[11:32:56] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:32:56] Blending: optimization starts with equal weights and score \u001b[1m0.8712273828878921\u001b[0m\n",
      "[11:32:56] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8767285000118304\u001b[0m, weights = \u001b[1m[0.84852064 0.         0.1514794 ]\u001b[0m\n",
      "[11:32:56] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8767285000118304\u001b[0m, weights = \u001b[1m[0.84852064 0.         0.1514794 ]\u001b[0m\n",
      "[11:32:56] Blending: no score update. Terminated\n",
      "\n",
      "[11:32:56] \u001b[1mAutoml preset training completed in 213.89 seconds\u001b[0m\n",
      "\n",
      "[11:32:56] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.84852 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.15148 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[11:32:56] ==================================================\n",
      "[11:32:56] Start 2 automl preset configuration:\n",
      "[11:32:56] \u001b[1mconf_2_select_mode_1_no_typ.yml\u001b[0m, random state: {'reader_params': {'random_state': 44}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:32:56] Stdout logging level is INFO.\n",
      "[11:32:56] Task: binary\n",
      "\n",
      "[11:32:56] Start automl preset with listed constraints:\n",
      "[11:32:56] - time: 3218.28 seconds\n",
      "[11:32:56] - CPU: 4 cores\n",
      "[11:32:56] - memory: 16 GB\n",
      "\n",
      "[11:32:56] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[11:32:56] Layer \u001b[1m1\u001b[0m train process start. Time left 3218.25 secs\n",
      "[11:32:56] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:32:57] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.872888703358808\u001b[0m\n",
      "[11:32:57] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:32:57] Time left 3217.42 secs\n",
      "\n",
      "[11:32:58] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:32:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:33:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8541975805224963\u001b[0m\n",
      "[11:33:02] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:33:02] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:36:08] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:36:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:36:10] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8582824346203637\u001b[0m\n",
      "[11:36:10] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:36:10] Time left 3024.46 secs\n",
      "\n",
      "[11:36:10] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:36:10] Blending: optimization starts with equal weights and score \u001b[1m0.8701905363884955\u001b[0m\n",
      "[11:36:10] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8742855307944256\u001b[0m, weights = \u001b[1m[0.7594116  0.12909313 0.11149535]\u001b[0m\n",
      "[11:36:10] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8742855307944256\u001b[0m, weights = \u001b[1m[0.7594116  0.12909313 0.11149535]\u001b[0m\n",
      "[11:36:10] Blending: no score update. Terminated\n",
      "\n",
      "[11:36:10] \u001b[1mAutoml preset training completed in 193.90 seconds\u001b[0m\n",
      "\n",
      "[11:36:10] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.75941 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.12909 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.11150 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[11:36:10] ==================================================\n",
      "[11:36:10] Start 3 automl preset configuration:\n",
      "[11:36:10] \u001b[1mconf_3_sel_type_1_no_inter_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 45}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:36:10] Stdout logging level is INFO.\n",
      "[11:36:10] Task: binary\n",
      "\n",
      "[11:36:10] Start automl preset with listed constraints:\n",
      "[11:36:10] - time: 3024.35 seconds\n",
      "[11:36:10] - CPU: 4 cores\n",
      "[11:36:10] - memory: 16 GB\n",
      "\n",
      "[11:36:10] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[11:36:12] Layer \u001b[1m1\u001b[0m train process start. Time left 3021.55 secs\n",
      "[11:36:12] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:36:13] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8698981575060251\u001b[0m\n",
      "[11:36:13] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:36:13] Time left 3020.76 secs\n",
      "\n",
      "[11:36:14] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:36:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:36:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8568315255417459\u001b[0m\n",
      "[11:36:19] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:36:19] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:39:53] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:39:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:39:56] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8414300876460628\u001b[0m\n",
      "[11:39:56] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:39:56] Time left 2798.39 secs\n",
      "\n",
      "[11:39:56] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:39:56] Blending: optimization starts with equal weights and score \u001b[1m0.8680289607198267\u001b[0m\n",
      "[11:39:56] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8712679441201423\u001b[0m, weights = \u001b[1m[0.71032554 0.15319532 0.13647908]\u001b[0m\n",
      "[11:39:56] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8712679441201423\u001b[0m, weights = \u001b[1m[0.71032554 0.15319532 0.13647908]\u001b[0m\n",
      "[11:39:56] Blending: no score update. Terminated\n",
      "\n",
      "[11:39:56] \u001b[1mAutoml preset training completed in 226.04 seconds\u001b[0m\n",
      "\n",
      "[11:39:56] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.71033 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.15320 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.13648 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[11:39:56] ==================================================\n",
      "[11:39:56] Start 4 automl preset configuration:\n",
      "[11:39:56] \u001b[1mconf_4_sel_type_0_no_int.yml\u001b[0m, random state: {'reader_params': {'random_state': 46}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:39:56] Stdout logging level is INFO.\n",
      "[11:39:56] Task: binary\n",
      "\n",
      "[11:39:56] Start automl preset with listed constraints:\n",
      "[11:39:56] - time: 2798.28 seconds\n",
      "[11:39:56] - CPU: 4 cores\n",
      "[11:39:56] - memory: 16 GB\n",
      "\n",
      "[11:39:56] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[11:39:56] Layer \u001b[1m1\u001b[0m train process start. Time left 2798.00 secs\n",
      "[11:39:56] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:39:57] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8694604342079912\u001b[0m\n",
      "[11:39:57] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:39:57] Time left 2797.27 secs\n",
      "\n",
      "[11:39:57] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:40:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8499741422144405\u001b[0m\n",
      "[11:40:00] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:40:00] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:41:53] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:41:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:41:56] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8534809987527421\u001b[0m\n",
      "[11:41:56] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:41:56] Time left 2678.43 secs\n",
      "\n",
      "[11:41:56] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:41:56] Blending: optimization starts with equal weights and score \u001b[1m0.863923826005834\u001b[0m\n",
      "[11:41:56] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8697992895024151\u001b[0m, weights = \u001b[1m[0.8531614 0.1468386 0.       ]\u001b[0m\n",
      "[11:41:56] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8697992895024151\u001b[0m, weights = \u001b[1m[0.8531614 0.1468386 0.       ]\u001b[0m\n",
      "[11:41:56] Blending: no score update. Terminated\n",
      "\n",
      "[11:41:56] \u001b[1mAutoml preset training completed in 119.94 seconds\u001b[0m\n",
      "\n",
      "[11:41:56] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.85316 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.14684 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "[11:41:56] ==================================================\n",
      "[11:41:56] Start 5 automl preset configuration:\n",
      "[11:41:56] \u001b[1mconf_5_sel_type_1_tuning_full.yml\u001b[0m, random state: {'reader_params': {'random_state': 47}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:41:56] Stdout logging level is INFO.\n",
      "[11:41:56] Task: binary\n",
      "\n",
      "[11:41:56] Start automl preset with listed constraints:\n",
      "[11:41:56] - time: 2678.31 seconds\n",
      "[11:41:56] - CPU: 4 cores\n",
      "[11:41:56] - memory: 16 GB\n",
      "\n",
      "[11:41:56] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[11:41:56] Layer \u001b[1m1\u001b[0m train process start. Time left 2678.02 secs\n",
      "[11:41:56] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:41:57] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8699513941233534\u001b[0m\n",
      "[11:41:57] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:41:57] Time left 2677.23 secs\n",
      "\n",
      "[11:41:58] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:41:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:42:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.850632417212835\u001b[0m\n",
      "[11:42:02] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:42:02] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:42:02] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:42:14] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8230845803095498\u001b[0m\n",
      "[11:42:14] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:42:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:42:21] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8471137303151269\u001b[0m\n",
      "[11:42:21] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:42:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:42:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8416937356556892\u001b[0m\n",
      "[11:42:27] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:42:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:42:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8288011789798174\u001b[0m\n",
      "[11:42:36] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:42:36] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:42:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.849161227518092\u001b[0m\n",
      "[11:42:43] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:42:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:42:47] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8549969748080946\u001b[0m\n",
      "[11:42:47] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:42:47] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:42:56] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8260024539545512\u001b[0m\n",
      "[11:42:56] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:42:56] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:43:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8388417740130946\u001b[0m\n",
      "[11:43:03] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:43:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:43:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8428471956978053\u001b[0m\n",
      "[11:43:11] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:43:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:43:18] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8458935132449323\u001b[0m\n",
      "[11:43:18] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:43:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:43:24] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8546251635124675\u001b[0m\n",
      "[11:43:24] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:43:24] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:43:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8528239912928554\u001b[0m\n",
      "[11:43:29] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:43:29] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:43:33] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8528235687800195\u001b[0m\n",
      "[11:43:33] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:43:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:43:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8496124712268759\u001b[0m\n",
      "[11:43:37] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:43:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:43:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8443471162653922\u001b[0m\n",
      "[11:43:43] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:43:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:43:48] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.850145682425832\u001b[0m\n",
      "[11:43:48] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:43:48] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:43:54] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8441147342056252\u001b[0m\n",
      "[11:43:54] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:43:54] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:44:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8484277452349002\u001b[0m\n",
      "[11:44:00] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:44:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:44:06] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8476055352561612\u001b[0m\n",
      "[11:44:06] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:44:06] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:44:15] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8289718741655371\u001b[0m\n",
      "[11:44:15] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:44:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:44:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8519548823893269\u001b[0m\n",
      "[11:44:19] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:44:19] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:44:25] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8529942639657393\u001b[0m\n",
      "[11:44:25] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:44:25] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:44:31] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8509450767114305\u001b[0m\n",
      "[11:44:31] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:44:31] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:44:38] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8541891302657775\u001b[0m\n",
      "[11:44:38] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:44:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:44:44] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8449132834655517\u001b[0m\n",
      "[11:44:44] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:44:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:44:48] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8537564771217749\u001b[0m\n",
      "[11:44:48] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:44:48] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:44:54] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8458563321153697\u001b[0m\n",
      "[11:44:54] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:44:55] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:45:01] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8391366879725807\u001b[0m\n",
      "[11:45:01] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:45:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:45:06] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8530990471490524\u001b[0m\n",
      "[11:45:06] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:45:06] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:45:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8478877738305689\u001b[0m\n",
      "[11:45:11] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:45:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:45:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8453594570203042\u001b[0m\n",
      "[11:45:17] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:45:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:45:21] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.85387562574151\u001b[0m\n",
      "[11:45:21] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:45:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:45:27] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8557304570912865\u001b[0m\n",
      "[11:45:27] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:45:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:45:34] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8554913148261446\u001b[0m\n",
      "[11:45:34] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:45:34] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:45:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8542423668831058\u001b[0m\n",
      "[11:45:40] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:45:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:45:46] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8484404206199784\u001b[0m\n",
      "[11:45:46] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:45:46] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:45:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8542457469857935\u001b[0m\n",
      "[11:45:53] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:45:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:46:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8376849338682909\u001b[0m\n",
      "[11:46:00] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:46:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:46:06] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8487066037066207\u001b[0m\n",
      "[11:46:06] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:46:06] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:46:15] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8408782858823252\u001b[0m\n",
      "[11:46:15] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:46:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:46:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8537336614286343\u001b[0m\n",
      "[11:46:22] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:46:22] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:46:28] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8549564135758444\u001b[0m\n",
      "[11:46:28] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:46:28] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:46:34] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8530846817126305\u001b[0m\n",
      "[11:46:34] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:46:34] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:46:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8555361011867539\u001b[0m\n",
      "[11:46:40] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:46:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:46:46] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8486432267812295\u001b[0m\n",
      "[11:46:46] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:46:46] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:46:52] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8447924447944728\u001b[0m\n",
      "[11:46:52] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:46:52] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:46:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8535308552673829\u001b[0m\n",
      "[11:46:59] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:46:59] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:47:06] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8540716716973861\u001b[0m\n",
      "[11:47:06] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:47:06] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:47:06] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:47:08] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8544553133524195\u001b[0m\n",
      "[11:47:08] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:47:08] Time left 2366.11 secs\n",
      "\n",
      "[11:47:08] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:47:08] Blending: optimization starts with equal weights and score \u001b[1m0.8656130323239222\u001b[0m\n",
      "[11:47:08] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8706155843014511\u001b[0m, weights = \u001b[1m[0.8024552  0.09244244 0.10510243]\u001b[0m\n",
      "[11:47:08] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8706155843014511\u001b[0m, weights = \u001b[1m[0.8024552  0.09244244 0.10510243]\u001b[0m\n",
      "[11:47:08] Blending: no score update. Terminated\n",
      "\n",
      "[11:47:08] \u001b[1mAutoml preset training completed in 312.29 seconds\u001b[0m\n",
      "\n",
      "[11:47:08] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.80246 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.09244 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.10510 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[11:47:08] ==================================================\n",
      "[11:47:08] Start 6 automl preset configuration:\n",
      "[11:47:08] \u001b[1mconf_6_sel_type_1_tuning_full_no_int_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 48}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:47:08] Stdout logging level is INFO.\n",
      "[11:47:08] Task: binary\n",
      "\n",
      "[11:47:08] Start automl preset with listed constraints:\n",
      "[11:47:08] - time: 2365.99 seconds\n",
      "[11:47:08] - CPU: 4 cores\n",
      "[11:47:08] - memory: 16 GB\n",
      "\n",
      "[11:47:08] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[11:47:12] Layer \u001b[1m1\u001b[0m train process start. Time left 2362.10 secs\n",
      "[11:47:12] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:47:14] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8755125080699953\u001b[0m\n",
      "[11:47:14] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:47:14] Time left 2360.28 secs\n",
      "\n",
      "[11:47:18] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:47:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:47:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8569033527238558\u001b[0m\n",
      "[11:47:22] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:47:22] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:49:18] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:49:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:49:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8623563033844969\u001b[0m\n",
      "[11:49:20] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:49:20] Time left 2233.87 secs\n",
      "\n",
      "[11:49:20] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:49:20] Blending: optimization starts with equal weights and score \u001b[1m0.8718028453704423\u001b[0m\n",
      "[11:49:20] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.876379504409344\u001b[0m, weights = \u001b[1m[0.81155336 0.09111831 0.09732836]\u001b[0m\n",
      "[11:49:20] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.876379504409344\u001b[0m, weights = \u001b[1m[0.81155336 0.09111831 0.09732836]\u001b[0m\n",
      "[11:49:20] Blending: no score update. Terminated\n",
      "\n",
      "[11:49:20] \u001b[1mAutoml preset training completed in 132.21 seconds\u001b[0m\n",
      "\n",
      "[11:49:20] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.81155 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.09112 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.09733 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[11:49:20] ==================================================\n",
      "[11:49:20] ==================================================\n",
      "[11:49:20] Start 0 automl preset configuration:\n",
      "[11:49:20] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 49}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:49:20] Stdout logging level is INFO.\n",
      "[11:49:20] Task: binary\n",
      "\n",
      "[11:49:20] Start automl preset with listed constraints:\n",
      "[11:49:20] - time: 2233.74 seconds\n",
      "[11:49:20] - CPU: 4 cores\n",
      "[11:49:20] - memory: 16 GB\n",
      "\n",
      "[11:49:20] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[11:49:21] Layer \u001b[1m1\u001b[0m train process start. Time left 2233.45 secs\n",
      "[11:49:21] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:49:21] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8676305311155353\u001b[0m\n",
      "[11:49:21] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:49:21] Time left 2232.69 secs\n",
      "\n",
      "[11:49:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:49:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8527652620086598\u001b[0m\n",
      "[11:49:26] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:49:26] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:52:01] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:52:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:52:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8542364517034026\u001b[0m\n",
      "[11:52:02] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:52:02] Time left 2072.06 secs\n",
      "\n",
      "[11:52:02] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:52:02] Blending: optimization starts with equal weights and score \u001b[1m0.8655479653471873\u001b[0m\n",
      "[11:52:02] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8690438365517545\u001b[0m, weights = \u001b[1m[0.719622   0.12033786 0.16004014]\u001b[0m\n",
      "[11:52:02] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8690565119368326\u001b[0m, weights = \u001b[1m[0.71350914 0.11656724 0.16992366]\u001b[0m\n",
      "[11:52:02] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8690877778866921\u001b[0m, weights = \u001b[1m[0.74988407 0.05269736 0.19741859]\u001b[0m\n",
      "[11:52:02] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.869081862706989\u001b[0m, weights = \u001b[1m[0.7399576  0.05478879 0.20525365]\u001b[0m\n",
      "[11:52:02] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.869081862706989\u001b[0m, weights = \u001b[1m[0.7399576  0.05478879 0.20525365]\u001b[0m\n",
      "[11:52:02] Blending: no score update. Terminated\n",
      "\n",
      "[11:52:02] \u001b[1mAutoml preset training completed in 161.89 seconds\u001b[0m\n",
      "\n",
      "[11:52:02] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.73996 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.05479 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.20525 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[11:52:02] ==================================================\n",
      "[11:52:02] Start 1 automl preset configuration:\n",
      "[11:52:02] \u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 50}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:52:02] Stdout logging level is INFO.\n",
      "[11:52:02] Task: binary\n",
      "\n",
      "[11:52:02] Start automl preset with listed constraints:\n",
      "[11:52:02] - time: 2071.83 seconds\n",
      "[11:52:02] - CPU: 4 cores\n",
      "[11:52:02] - memory: 16 GB\n",
      "\n",
      "[11:52:02] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[11:52:02] Layer \u001b[1m1\u001b[0m train process start. Time left 2071.53 secs\n",
      "[11:52:02] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:52:03] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8696640853949142\u001b[0m\n",
      "[11:52:03] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:52:03] Time left 2070.77 secs\n",
      "\n",
      "[11:52:04] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:52:04] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:52:08] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.847296255860253\u001b[0m\n",
      "[11:52:08] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:52:08] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:55:05] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:55:05] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:55:06] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8476891927976773\u001b[0m\n",
      "[11:55:06] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:55:06] Time left 1887.77 secs\n",
      "\n",
      "[11:55:06] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:55:06] Blending: optimization starts with equal weights and score \u001b[1m0.8638908700046307\u001b[0m\n",
      "[11:55:06] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8701753259264017\u001b[0m, weights = \u001b[1m[0.86489916 0.06648307 0.06861775]\u001b[0m\n",
      "[11:55:06] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8701753259264017\u001b[0m, weights = \u001b[1m[0.86489916 0.06648307 0.06861775]\u001b[0m\n",
      "[11:55:06] Blending: no score update. Terminated\n",
      "\n",
      "[11:55:06] \u001b[1mAutoml preset training completed in 184.14 seconds\u001b[0m\n",
      "\n",
      "[11:55:06] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.86490 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.06648 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.06862 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[11:55:06] ==================================================\n",
      "[11:55:06] Start 2 automl preset configuration:\n",
      "[11:55:06] \u001b[1mconf_2_select_mode_1_no_typ.yml\u001b[0m, random state: {'reader_params': {'random_state': 51}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:55:06] Stdout logging level is INFO.\n",
      "[11:55:06] Task: binary\n",
      "\n",
      "[11:55:06] Start automl preset with listed constraints:\n",
      "[11:55:06] - time: 1887.66 seconds\n",
      "[11:55:06] - CPU: 4 cores\n",
      "[11:55:06] - memory: 16 GB\n",
      "\n",
      "[11:55:06] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[11:55:06] Layer \u001b[1m1\u001b[0m train process start. Time left 1887.63 secs\n",
      "[11:55:06] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:55:07] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.866696355235272\u001b[0m\n",
      "[11:55:07] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:55:07] Time left 1886.82 secs\n",
      "\n",
      "[11:55:08] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:55:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:55:13] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8529815885806611\u001b[0m\n",
      "[11:55:13] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:55:13] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:57:39] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:57:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:57:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.847437375147457\u001b[0m\n",
      "[11:57:40] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:57:40] Time left 1733.60 secs\n",
      "\n",
      "[11:57:40] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:57:40] Blending: optimization starts with equal weights and score \u001b[1m0.8638798846708963\u001b[0m\n",
      "[11:57:40] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8679402330242793\u001b[0m, weights = \u001b[1m[0.7516049  0.         0.24839513]\u001b[0m\n",
      "[11:57:40] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8679740340511544\u001b[0m, weights = \u001b[1m[0.76393205 0.         0.23606798]\u001b[0m\n",
      "[11:57:40] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8679740340511544\u001b[0m, weights = \u001b[1m[0.76393205 0.         0.23606798]\u001b[0m\n",
      "[11:57:40] Blending: no score update. Terminated\n",
      "\n",
      "[11:57:40] \u001b[1mAutoml preset training completed in 154.19 seconds\u001b[0m\n",
      "\n",
      "[11:57:40] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.76393 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.23607 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[11:57:41] ==================================================\n",
      "[11:57:41] Start 3 automl preset configuration:\n",
      "[11:57:41] \u001b[1mconf_3_sel_type_1_no_inter_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 52}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:57:41] Stdout logging level is INFO.\n",
      "[11:57:41] Task: binary\n",
      "\n",
      "[11:57:41] Start automl preset with listed constraints:\n",
      "[11:57:41] - time: 1733.44 seconds\n",
      "[11:57:41] - CPU: 4 cores\n",
      "[11:57:41] - memory: 16 GB\n",
      "\n",
      "[11:57:41] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[11:57:44] Layer \u001b[1m1\u001b[0m train process start. Time left 1730.46 secs\n",
      "[11:57:44] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:57:44] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8752251993415561\u001b[0m\n",
      "[11:57:44] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:57:44] Time left 1729.65 secs\n",
      "\n",
      "[11:57:45] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:57:45] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:57:49] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8599615006303892\u001b[0m\n",
      "[11:57:49] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:57:49] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[11:59:14] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[11:59:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[11:59:15] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8600789591987803\u001b[0m\n",
      "[11:59:15] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:59:15] Time left 1638.54 secs\n",
      "\n",
      "[11:59:15] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[11:59:15] Blending: optimization starts with equal weights and score \u001b[1m0.8730146121839183\u001b[0m\n",
      "[11:59:15] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.876682023599877\u001b[0m, weights = \u001b[1m[0.70733845 0.09370673 0.19895484]\u001b[0m\n",
      "[11:59:16] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8767893418602057\u001b[0m, weights = \u001b[1m[0.7085183  0.05541373 0.23606798]\u001b[0m\n",
      "[11:59:16] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8768713093503779\u001b[0m, weights = \u001b[1m[0.76393205 0.         0.23606798]\u001b[0m\n",
      "[11:59:16] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.8768713093503779\u001b[0m, weights = \u001b[1m[0.76393205 0.         0.23606798]\u001b[0m\n",
      "[11:59:16] Blending: no score update. Terminated\n",
      "\n",
      "[11:59:16] \u001b[1mAutoml preset training completed in 95.08 seconds\u001b[0m\n",
      "\n",
      "[11:59:16] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.76393 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.23607 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[11:59:16] ==================================================\n",
      "[11:59:16] Start 4 automl preset configuration:\n",
      "[11:59:16] \u001b[1mconf_4_sel_type_0_no_int.yml\u001b[0m, random state: {'reader_params': {'random_state': 53}, 'general_params': {'return_all_predictions': False}}\n",
      "[11:59:16] Stdout logging level is INFO.\n",
      "[11:59:16] Task: binary\n",
      "\n",
      "[11:59:16] Start automl preset with listed constraints:\n",
      "[11:59:16] - time: 1638.34 seconds\n",
      "[11:59:16] - CPU: 4 cores\n",
      "[11:59:16] - memory: 16 GB\n",
      "\n",
      "[11:59:16] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[11:59:16] Layer \u001b[1m1\u001b[0m train process start. Time left 1638.04 secs\n",
      "[11:59:16] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[11:59:17] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8706341748662325\u001b[0m\n",
      "[11:59:17] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[11:59:17] Time left 1637.17 secs\n",
      "\n",
      "[11:59:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[11:59:21] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8505225638754904\u001b[0m\n",
      "[11:59:21] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[11:59:21] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:01:31] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[12:01:31] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:01:33] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8559400234579126\u001b[0m\n",
      "[12:01:33] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:01:33] Time left 1501.31 secs\n",
      "\n",
      "[12:01:33] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:01:33] Blending: optimization starts with equal weights and score \u001b[1m0.8662713073223164\u001b[0m\n",
      "[12:01:33] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8712772394025331\u001b[0m, weights = \u001b[1m[0.7868044  0.0520701  0.16112556]\u001b[0m\n",
      "[12:01:33] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8712476635040173\u001b[0m, weights = \u001b[1m[0.78213483 0.05769588 0.1601693 ]\u001b[0m\n",
      "[12:01:33] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8712476635040173\u001b[0m, weights = \u001b[1m[0.78213483 0.05769588 0.1601693 ]\u001b[0m\n",
      "[12:01:33] Blending: no score update. Terminated\n",
      "\n",
      "[12:01:33] \u001b[1mAutoml preset training completed in 137.16 seconds\u001b[0m\n",
      "\n",
      "[12:01:33] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.78213 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.05770 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.16017 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[12:01:33] ==================================================\n",
      "[12:01:33] Start 5 automl preset configuration:\n",
      "[12:01:33] \u001b[1mconf_5_sel_type_1_tuning_full.yml\u001b[0m, random state: {'reader_params': {'random_state': 54}, 'general_params': {'return_all_predictions': False}}\n",
      "[12:01:33] Stdout logging level is INFO.\n",
      "[12:01:33] Task: binary\n",
      "\n",
      "[12:01:33] Start automl preset with listed constraints:\n",
      "[12:01:33] - time: 1501.15 seconds\n",
      "[12:01:33] - CPU: 4 cores\n",
      "[12:01:33] - memory: 16 GB\n",
      "\n",
      "[12:01:33] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[12:01:33] Layer \u001b[1m1\u001b[0m train process start. Time left 1500.85 secs\n",
      "[12:01:33] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:01:34] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8719972012749747\u001b[0m\n",
      "[12:01:34] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:01:34] Time left 1499.72 secs\n",
      "\n",
      "[12:01:35] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:01:35] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[12:01:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8504752424378654\u001b[0m\n",
      "[12:01:40] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:01:40] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:01:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:01:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8292000310969447\u001b[0m\n",
      "[12:01:53] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:01:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:02:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8482147987655865\u001b[0m\n",
      "[12:02:02] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:02:02] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:02:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8319869257628046\u001b[0m\n",
      "[12:02:12] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:02:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:02:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.81925492396459\u001b[0m\n",
      "[12:02:29] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:02:29] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:02:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8387133301109688\u001b[0m\n",
      "[12:02:37] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:02:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:02:41] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8512543561073386\u001b[0m\n",
      "[12:02:41] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:02:41] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:02:47] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8417824633512367\u001b[0m\n",
      "[12:02:47] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:02:47] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:02:55] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.850977187686962\u001b[0m\n",
      "[12:02:55] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:02:55] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:03:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8426503047162572\u001b[0m\n",
      "[12:03:02] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:03:02] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:03:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8380677304976524\u001b[0m\n",
      "[12:03:11] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:03:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:03:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8507650862433201\u001b[0m\n",
      "[12:03:17] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:03:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:03:19] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.852588651643237\u001b[0m\n",
      "[12:03:19] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:03:19] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:03:23] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8549986648594385\u001b[0m\n",
      "[12:03:23] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:03:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:03:28] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8533424145425537\u001b[0m\n",
      "[12:03:28] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:03:28] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:03:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8402774726296185\u001b[0m\n",
      "[12:03:35] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:03:35] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:03:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8362526153544545\u001b[0m\n",
      "[12:03:43] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:03:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:03:50] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8388282536023444\u001b[0m\n",
      "[12:03:50] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:03:50] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:04:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.846444469982998\u001b[0m\n",
      "[12:04:00] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:04:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:04:06] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8469312047700008\u001b[0m\n",
      "[12:04:06] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:04:06] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:04:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8246022464162461\u001b[0m\n",
      "[12:04:16] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:04:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:04:25] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8407722351605043\u001b[0m\n",
      "[12:04:25] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:04:25] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:04:28] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8538477398943379\u001b[0m\n",
      "[12:04:28] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:04:28] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:04:34] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8452010147068268\u001b[0m\n",
      "[12:04:34] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:04:34] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:04:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8521310702419139\u001b[0m\n",
      "[12:04:37] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:04:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:04:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8516270124286375\u001b[0m\n",
      "[12:04:40] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:04:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:04:46] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8447763893067072\u001b[0m\n",
      "[12:04:46] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:04:46] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:04:52] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8438443259906238\u001b[0m\n",
      "[12:04:52] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:04:52] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:04:57] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8505732654158034\u001b[0m\n",
      "[12:04:57] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:04:57] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:05:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8487066037066205\u001b[0m\n",
      "[12:05:03] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:05:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8155807523432563\u001b[0m\n",
      "[12:05:11] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:05:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8428598710828835\u001b[0m\n",
      "[12:05:17] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:05:20] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8512366105682292\u001b[0m\n",
      "[12:05:20] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:20] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:05:23] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8500501945249097\u001b[0m\n",
      "[12:05:23] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:05:28] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8555056802625666\u001b[0m\n",
      "[12:05:28] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:28] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:05:32] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8470250026195796\u001b[0m\n",
      "[12:05:32] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:32] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:05:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.845143130448303\u001b[0m\n",
      "[12:05:37] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:05:42] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8533931160828666\u001b[0m\n",
      "[12:05:42] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:42] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:05:48] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8429925401133687\u001b[0m\n",
      "[12:05:48] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:48] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:05:51] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8495600796352194\u001b[0m\n",
      "[12:05:51] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:51] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:05:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8423334200893022\u001b[0m\n",
      "[12:05:58] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:05:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:06:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8503248278682707\u001b[0m\n",
      "[12:06:03] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:06:07] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8549090921382192\u001b[0m\n",
      "[12:06:07] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:07] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:06:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8519430520299207\u001b[0m\n",
      "[12:06:12] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:06:15] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8550088051675009\u001b[0m\n",
      "[12:06:15] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:15] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:06:18] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8543344746813408\u001b[0m\n",
      "[12:06:18] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:06:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8542296914980277\u001b[0m\n",
      "[12:06:22] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:22] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:06:25] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8537404216340092\u001b[0m\n",
      "[12:06:26] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:06:30] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8497299297952672\u001b[0m\n",
      "[12:06:30] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:30] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:06:36] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8511537980523848\u001b[0m\n",
      "[12:06:36] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:36] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:06:42] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8467782551233907\u001b[0m\n",
      "[12:06:42] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:42] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[12:06:42] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:06:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.847486386636426\u001b[0m\n",
      "[12:06:43] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:43] Time left 1191.14 secs\n",
      "\n",
      "[12:06:43] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:06:43] Blending: optimization starts with equal weights and score \u001b[1m0.8672794229488693\u001b[0m\n",
      "[12:06:43] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8727230783271196\u001b[0m, weights = \u001b[1m[0.77956885 0.0890693  0.13136183]\u001b[0m\n",
      "[12:06:43] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.872734063660854\u001b[0m, weights = \u001b[1m[0.80667204 0.07811777 0.11521021]\u001b[0m\n",
      "[12:06:43] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.872734063660854\u001b[0m, weights = \u001b[1m[0.80667204 0.07811777 0.11521021]\u001b[0m\n",
      "[12:06:43] Blending: no score update. Terminated\n",
      "\n",
      "[12:06:43] \u001b[1mAutoml preset training completed in 310.15 seconds\u001b[0m\n",
      "\n",
      "[12:06:43] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.80667 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.07812 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.11521 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[12:06:43] ==================================================\n",
      "[12:06:43] Start 6 automl preset configuration:\n",
      "[12:06:43] \u001b[1mconf_6_sel_type_1_tuning_full_no_int_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 55}, 'general_params': {'return_all_predictions': False}}\n",
      "[12:06:43] Stdout logging level is INFO.\n",
      "[12:06:43] Task: binary\n",
      "\n",
      "[12:06:43] Start automl preset with listed constraints:\n",
      "[12:06:43] - time: 1190.96 seconds\n",
      "[12:06:43] - CPU: 4 cores\n",
      "[12:06:43] - memory: 16 GB\n",
      "\n",
      "[12:06:43] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[12:06:46] Layer \u001b[1m1\u001b[0m train process start. Time left 1188.28 secs\n",
      "[12:06:46] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:06:48] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8751837930836339\u001b[0m\n",
      "[12:06:48] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:06:48] Time left 1186.36 secs\n",
      "\n",
      "[12:06:48] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:48] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[12:06:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8429316982649934\u001b[0m\n",
      "[12:06:53] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:06:53] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:08:23] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[12:08:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:08:24] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8375040983745087\u001b[0m\n",
      "[12:08:24] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:08:24] Time left 1089.64 secs\n",
      "\n",
      "[12:08:24] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:08:24] Blending: optimization starts with equal weights and score \u001b[1m0.8671678795601809\u001b[0m\n",
      "[12:08:24] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8766845586768925\u001b[0m, weights = \u001b[1m[0.80654746 0.         0.19345255]\u001b[0m\n",
      "[12:08:24] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8766845586768925\u001b[0m, weights = \u001b[1m[0.80654746 0.         0.19345255]\u001b[0m\n",
      "[12:08:24] Blending: no score update. Terminated\n",
      "\n",
      "[12:08:24] \u001b[1mAutoml preset training completed in 101.41 seconds\u001b[0m\n",
      "\n",
      "[12:08:24] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.80655 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.19345 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[12:08:24] ==================================================\n",
      "[12:08:24] ==================================================\n",
      "[12:08:24] Start 0 automl preset configuration:\n",
      "[12:08:24] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 56}, 'general_params': {'return_all_predictions': False}}\n",
      "[12:08:24] Stdout logging level is INFO.\n",
      "[12:08:24] Task: binary\n",
      "\n",
      "[12:08:24] Start automl preset with listed constraints:\n",
      "[12:08:24] - time: 1089.52 seconds\n",
      "[12:08:24] - CPU: 4 cores\n",
      "[12:08:24] - memory: 16 GB\n",
      "\n",
      "[12:08:24] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[12:08:25] Layer \u001b[1m1\u001b[0m train process start. Time left 1089.22 secs\n",
      "[12:08:25] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:08:26] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8723107057992421\u001b[0m\n",
      "[12:08:26] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:08:26] Time left 1088.41 secs\n",
      "\n",
      "[12:08:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[12:08:30] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8479621360896943\u001b[0m\n",
      "[12:08:30] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:08:30] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:09:51] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[12:09:51] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:09:52] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8556637000632079\u001b[0m\n",
      "[12:09:52] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:09:52] Time left 1001.92 secs\n",
      "\n",
      "[12:09:52] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:09:52] Blending: optimization starts with equal weights and score \u001b[1m0.8663600350178638\u001b[0m\n",
      "[12:09:52] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8725443553975171\u001b[0m, weights = \u001b[1m[0.8958775  0.05206127 0.05206127]\u001b[0m\n",
      "[12:09:52] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8725443553975171\u001b[0m, weights = \u001b[1m[0.8958775  0.05206127 0.05206127]\u001b[0m\n",
      "[12:09:52] Blending: no score update. Terminated\n",
      "\n",
      "[12:09:52] \u001b[1mAutoml preset training completed in 87.69 seconds\u001b[0m\n",
      "\n",
      "[12:09:52] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.89588 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.05206 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.05206 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[12:09:52] ==================================================\n",
      "[12:09:52] Start 1 automl preset configuration:\n",
      "[12:09:52] \u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 57}, 'general_params': {'return_all_predictions': False}}\n",
      "[12:09:52] Stdout logging level is INFO.\n",
      "[12:09:52] Task: binary\n",
      "\n",
      "[12:09:52] Start automl preset with listed constraints:\n",
      "[12:09:52] - time: 1001.80 seconds\n",
      "[12:09:52] - CPU: 4 cores\n",
      "[12:09:52] - memory: 16 GB\n",
      "\n",
      "[12:09:52] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[12:09:52] Layer \u001b[1m1\u001b[0m train process start. Time left 1001.51 secs\n",
      "[12:09:52] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:09:53] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8702108170046207\u001b[0m\n",
      "[12:09:53] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:09:53] Time left 1000.78 secs\n",
      "\n",
      "[12:09:54] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:09:54] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[12:09:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8545077049440764\u001b[0m\n",
      "[12:09:59] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:09:59] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:12:22] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[12:12:22] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:12:23] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8497214795385484\u001b[0m\n",
      "[12:12:23] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:12:23] Time left 850.48 secs\n",
      "\n",
      "[12:12:23] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:12:23] Blending: optimization starts with equal weights and score \u001b[1m0.8667301562621471\u001b[0m\n",
      "[12:12:24] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8713009001213456\u001b[0m, weights = \u001b[1m[0.7699855  0.06094949 0.16906501]\u001b[0m\n",
      "[12:12:24] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8713190681732912\u001b[0m, weights = \u001b[1m[0.7747965  0.05967467 0.16552883]\u001b[0m\n",
      "[12:12:24] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8713190681732912\u001b[0m, weights = \u001b[1m[0.7747965  0.05967467 0.16552883]\u001b[0m\n",
      "[12:12:24] Blending: no score update. Terminated\n",
      "\n",
      "[12:12:24] \u001b[1mAutoml preset training completed in 151.44 seconds\u001b[0m\n",
      "\n",
      "[12:12:24] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.77480 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.05967 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.16553 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[12:12:24] ==================================================\n",
      "[12:12:24] Start 2 automl preset configuration:\n",
      "[12:12:24] \u001b[1mconf_2_select_mode_1_no_typ.yml\u001b[0m, random state: {'reader_params': {'random_state': 58}, 'general_params': {'return_all_predictions': False}}\n",
      "[12:12:24] Stdout logging level is INFO.\n",
      "[12:12:24] Task: binary\n",
      "\n",
      "[12:12:24] Start automl preset with listed constraints:\n",
      "[12:12:24] - time: 850.33 seconds\n",
      "[12:12:24] - CPU: 4 cores\n",
      "[12:12:24] - memory: 16 GB\n",
      "\n",
      "[12:12:24] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[12:12:24] Layer \u001b[1m1\u001b[0m train process start. Time left 850.30 secs\n",
      "[12:12:24] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:12:25] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8699361836612597\u001b[0m\n",
      "[12:12:25] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:12:25] Time left 849.43 secs\n",
      "\n",
      "[12:12:25] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:12:25] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[12:12:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8525835814892057\u001b[0m\n",
      "[12:12:29] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:12:29] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:13:58] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[12:13:58] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:13:59] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8528320190367384\u001b[0m\n",
      "[12:13:59] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:13:59] Time left 754.84 secs\n",
      "\n",
      "[12:13:59] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:13:59] Blending: optimization starts with equal weights and score \u001b[1m0.8666295982071935\u001b[0m\n",
      "[12:13:59] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8709916207254377\u001b[0m, weights = \u001b[1m[0.7601826  0.         0.23981738]\u001b[0m\n",
      "[12:13:59] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8709899306740939\u001b[0m, weights = \u001b[1m[0.7601826  0.         0.23981738]\u001b[0m\n",
      "[12:13:59] Blending: no score update. Terminated\n",
      "\n",
      "[12:13:59] \u001b[1mAutoml preset training completed in 95.57 seconds\u001b[0m\n",
      "\n",
      "[12:13:59] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.76018 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.23982 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[12:13:59] ==================================================\n",
      "[12:13:59] Start 3 automl preset configuration:\n",
      "[12:13:59] \u001b[1mconf_3_sel_type_1_no_inter_lgbm.yml\u001b[0m, random state: {'reader_params': {'random_state': 59}, 'general_params': {'return_all_predictions': False}}\n",
      "[12:13:59] Stdout logging level is INFO.\n",
      "[12:13:59] Task: binary\n",
      "\n",
      "[12:13:59] Start automl preset with listed constraints:\n",
      "[12:13:59] - time: 754.73 seconds\n",
      "[12:13:59] - CPU: 4 cores\n",
      "[12:13:59] - memory: 16 GB\n",
      "\n",
      "[12:13:59] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[12:14:00] Layer \u001b[1m1\u001b[0m train process start. Time left 754.45 secs\n",
      "[12:14:00] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:14:00] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8677306666576531\u001b[0m\n",
      "[12:14:00] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:14:00] Time left 753.57 secs\n",
      "\n",
      "[12:14:01] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:14:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[12:14:06] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8518940405409516\u001b[0m\n",
      "[12:14:06] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:14:06] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:15:23] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[12:15:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:15:25] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8362948666380484\u001b[0m\n",
      "[12:15:25] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:15:25] Time left 668.81 secs\n",
      "\n",
      "[12:15:25] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:15:25] Blending: optimization starts with equal weights and score \u001b[1m0.8649479971201525\u001b[0m\n",
      "[12:15:25] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8699649145341035\u001b[0m, weights = \u001b[1m[0.73704857 0.26295146 0.        ]\u001b[0m\n",
      "[12:15:25] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8700020956636664\u001b[0m, weights = \u001b[1m[0.67818725 0.32181275 0.        ]\u001b[0m\n",
      "[12:15:25] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8700020956636664\u001b[0m, weights = \u001b[1m[0.67818725 0.32181275 0.        ]\u001b[0m\n",
      "[12:15:25] Blending: no score update. Terminated\n",
      "\n",
      "[12:15:25] \u001b[1mAutoml preset training completed in 86.05 seconds\u001b[0m\n",
      "\n",
      "[12:15:25] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.67819 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.32181 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) \n",
      "\n",
      "[12:15:25] ==================================================\n",
      "[12:15:25] Start 4 automl preset configuration:\n",
      "[12:15:25] \u001b[1mconf_4_sel_type_0_no_int.yml\u001b[0m, random state: {'reader_params': {'random_state': 60}, 'general_params': {'return_all_predictions': False}}\n",
      "[12:15:25] Stdout logging level is INFO.\n",
      "[12:15:25] Task: binary\n",
      "\n",
      "[12:15:25] Start automl preset with listed constraints:\n",
      "[12:15:25] - time: 668.66 seconds\n",
      "[12:15:25] - CPU: 4 cores\n",
      "[12:15:25] - memory: 16 GB\n",
      "\n",
      "[12:15:25] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[12:15:26] Layer \u001b[1m1\u001b[0m train process start. Time left 668.37 secs\n",
      "[12:15:26] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:15:26] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8724484449837587\u001b[0m\n",
      "[12:15:26] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:15:26] Time left 667.57 secs\n",
      "\n",
      "[12:15:26] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[12:15:30] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8505597450050533\u001b[0m\n",
      "[12:15:30] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:15:30] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[12:18:33] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[12:18:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:18:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8579604798393774\u001b[0m\n",
      "[12:18:35] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:18:35] Time left 479.08 secs\n",
      "\n",
      "[12:18:35] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:18:35] Blending: optimization starts with equal weights and score \u001b[1m0.8674678636736982\u001b[0m\n",
      "[12:18:35] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.873289245527279\u001b[0m, weights = \u001b[1m[0.79155004 0.         0.20844999]\u001b[0m\n",
      "[12:18:35] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.873268119885482\u001b[0m, weights = \u001b[1m[0.79155004 0.         0.20844999]\u001b[0m\n",
      "[12:18:35] Blending: no score update. Terminated\n",
      "\n",
      "[12:18:35] \u001b[1mAutoml preset training completed in 189.67 seconds\u001b[0m\n",
      "\n",
      "[12:18:35] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.79155 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.20845 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[12:18:35] ==================================================\n",
      "[12:18:35] Start 5 automl preset configuration:\n",
      "[12:18:35] \u001b[1mconf_5_sel_type_1_tuning_full.yml\u001b[0m, random state: {'reader_params': {'random_state': 61}, 'general_params': {'return_all_predictions': False}}\n",
      "[12:18:35] Stdout logging level is INFO.\n",
      "[12:18:35] Task: binary\n",
      "\n",
      "[12:18:35] Start automl preset with listed constraints:\n",
      "[12:18:35] - time: 478.96 seconds\n",
      "[12:18:35] - CPU: 4 cores\n",
      "[12:18:35] - memory: 16 GB\n",
      "\n",
      "[12:18:35] \u001b[1mTrain data shape: (3145, 38)\u001b[0m\n",
      "\n",
      "[12:18:35] Layer \u001b[1m1\u001b[0m train process start. Time left 478.65 secs\n",
      "[12:18:35] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[12:18:36] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.8722988754398359\u001b[0m\n",
      "[12:18:36] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[12:18:36] Time left 477.82 secs\n",
      "\n",
      "[12:18:37] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:18:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[12:18:41] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.8504465115650214\u001b[0m\n",
      "[12:18:41] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:18:41] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 298.31 secs\n",
      "[12:18:41] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:18:56] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8309145881851889\u001b[0m\n",
      "[12:18:56] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:18:56] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:19:04] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8489677166392314\u001b[0m\n",
      "[12:19:04] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:19:04] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:19:11] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8397983430736626\u001b[0m\n",
      "[12:19:11] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:19:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:19:23] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8288020240054892\u001b[0m\n",
      "[12:19:23] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:19:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:19:31] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8460447728401989\u001b[0m\n",
      "[12:19:31] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:19:31] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:19:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8541865951887619\u001b[0m\n",
      "[12:19:35] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:19:35] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:19:44] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.82571430020044\u001b[0m\n",
      "[12:19:44] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:19:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:19:52] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8409196921402472\u001b[0m\n",
      "[12:19:52] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:19:52] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:20:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8448245557700043\u001b[0m\n",
      "[12:20:00] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:20:00] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:20:09] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8409501130644349\u001b[0m\n",
      "[12:20:09] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:20:09] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:20:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8526875196468469\u001b[0m\n",
      "[12:20:16] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:20:16] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:20:21] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8518855902842328\u001b[0m\n",
      "[12:20:21] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:20:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:20:25] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8525692160527838\u001b[0m\n",
      "[12:20:25] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:20:25] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:20:30] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8498389381069397\u001b[0m\n",
      "[12:20:30] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:20:30] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:20:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8463717977752163\u001b[0m\n",
      "[12:20:35] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:20:35] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:20:41] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8505512947483344\u001b[0m\n",
      "[12:20:41] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:20:41] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:20:46] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8173819245628684\u001b[0m\n",
      "[12:20:46] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:20:46] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:20:55] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8486643524230266\u001b[0m\n",
      "[12:20:55] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:20:55] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:03] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8470816193395956\u001b[0m\n",
      "[12:21:03] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:03] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8412196762537647\u001b[0m\n",
      "[12:21:12] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:12] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.848907719816528\u001b[0m\n",
      "[12:21:17] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:23] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8529452524767701\u001b[0m\n",
      "[12:21:23] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:23] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8508605741442425\u001b[0m\n",
      "[12:21:29] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:29] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:35] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8533601600816632\u001b[0m\n",
      "[12:21:35] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:35] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8535426856267894\u001b[0m\n",
      "[12:21:40] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:45] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8461208251506681\u001b[0m\n",
      "[12:21:45] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:45] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:49] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.850651852803288\u001b[0m\n",
      "[12:21:49] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:49] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8503366582276769\u001b[0m\n",
      "[12:21:53] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:21:57] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8535071945485705\u001b[0m\n",
      "[12:21:57] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:21:57] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8530466555573958\u001b[0m\n",
      "[12:22:02] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:02] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:06] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8523123282485323\u001b[0m\n",
      "[12:22:06] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:06] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:10] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.851764751613154\u001b[0m\n",
      "[12:22:10] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:10] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:14] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8538773157928539\u001b[0m\n",
      "[12:22:14] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:18] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8470689439545173\u001b[0m\n",
      "[12:22:18] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:18] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:24] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8475970849994423\u001b[0m\n",
      "[12:22:24] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:24] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8436753208562476\u001b[0m\n",
      "[12:22:29] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:29] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:33] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8536119777318835\u001b[0m\n",
      "[12:22:33] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:40] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8496800732806263\u001b[0m\n",
      "[12:22:40] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:40] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:44] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8512754817491355\u001b[0m\n",
      "[12:22:44] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:52] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8496648628185324\u001b[0m\n",
      "[12:22:52] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:52] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:22:56] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8533390344398661\u001b[0m\n",
      "[12:22:56] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:22:56] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:01] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8483280322056184\u001b[0m\n",
      "[12:23:01] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:01] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:05] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.854459538480779\u001b[0m\n",
      "[12:23:05] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:05] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:08] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8533829757748042\u001b[0m\n",
      "[12:23:08] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:09] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:14] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8498203475421583\u001b[0m\n",
      "[12:23:14] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:14] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:17] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8538663304591194\u001b[0m\n",
      "[12:23:17] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:17] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:21] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8541358936484491\u001b[0m\n",
      "[12:23:21] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:25] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8542449019601216\u001b[0m\n",
      "[12:23:25] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:25] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8514537821659022\u001b[0m\n",
      "[12:23:29] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:29] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:37] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8357278544122171\u001b[0m\n",
      "[12:23:37] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:37] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:45] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8328547671278252\u001b[0m\n",
      "[12:23:45] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:45] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[12:23:45] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[12:23:46] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.8508453636821487\u001b[0m\n",
      "[12:23:46] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[12:23:46] Time left 167.93 secs\n",
      "\n",
      "[12:23:46] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[12:23:46] Blending: optimization starts with equal weights and score \u001b[1m0.86641665173788\u001b[0m\n",
      "[12:23:46] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.872543932884681\u001b[0m, weights = \u001b[1m[0.8307815  0.05387082 0.1153477 ]\u001b[0m\n",
      "[12:23:46] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8725498480643841\u001b[0m, weights = \u001b[1m[0.87808466 0.         0.12191538]\u001b[0m\n",
      "[12:23:46] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8725498480643841\u001b[0m, weights = \u001b[1m[0.87808466 0.         0.12191538]\u001b[0m\n",
      "[12:23:46] Blending: no score update. Terminated\n",
      "\n",
      "[12:23:46] \u001b[1mAutoml preset training completed in 311.16 seconds\u001b[0m\n",
      "\n",
      "[12:23:46] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.87808 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.12192 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n",
      "[12:23:46] ==================================================\n",
      "[12:23:46] Blending: optimization starts with equal weights and score \u001b[1m0.8763879546660628\u001b[0m\n",
      "[12:23:46] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8800553660820216\u001b[0m, weights = \u001b[1m[0.         0.05043317 0.         0.         0.         0.\n",
      " 0.94956684]\u001b[0m\n",
      "[12:23:46] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.8801407136748814\u001b[0m, weights = \u001b[1m[0.         0.         0.         0.08903877 0.         0.\n",
      " 0.9109612 ]\u001b[0m\n",
      "[12:23:46] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.8801407136748814\u001b[0m, weights = \u001b[1m[0.         0.         0.         0.08903877 0.         0.\n",
      " 0.9109612 ]\u001b[0m\n",
      "[12:23:46] Blending: no score update. Terminated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_tr = automl.fit_predict(train_df, roles = roles, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5f2886c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T12:23:47.324641Z",
     "iopub.status.busy": "2023-01-20T12:23:47.324255Z",
     "iopub.status.idle": "2023-01-20T12:23:47.331435Z",
     "shell.execute_reply": "2023-01-20T12:23:47.330556Z"
    },
    "papermill": {
     "duration": 0.128796,
     "end_time": "2023-01-20T12:23:47.333173",
     "exception": false,
     "start_time": "2023-01-20T12:23:47.204377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36378852],\n",
       "       [0.1392905 ],\n",
       "       [0.0117404 ],\n",
       "       ...,\n",
       "       [0.05758971],\n",
       "       [0.0203717 ],\n",
       "       [0.06778043]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f8300aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T12:23:47.614203Z",
     "iopub.status.busy": "2023-01-20T12:23:47.613856Z",
     "iopub.status.idle": "2023-01-20T12:23:48.396633Z",
     "shell.execute_reply": "2023-01-20T12:23:48.395567Z"
    },
    "papermill": {
     "duration": 0.951648,
     "end_time": "2023-01-20T12:23:48.398692",
     "exception": false,
     "start_time": "2023-01-20T12:23:47.447044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15401532],\n",
       "       [0.22676158],\n",
       "       [0.03852388],\n",
       "       ...,\n",
       "       [0.02528773],\n",
       "       [0.0191116 ],\n",
       "       [0.00307779]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = automl.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef978ec",
   "metadata": {
    "papermill": {
     "duration": 0.11409,
     "end_time": "2023-01-20T12:23:48.627662",
     "exception": false,
     "start_time": "2023-01-20T12:23:48.513572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Making submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "677e1d98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T12:23:48.859922Z",
     "iopub.status.busy": "2023-01-20T12:23:48.859510Z",
     "iopub.status.idle": "2023-01-20T12:23:48.871957Z",
     "shell.execute_reply": "2023-01-20T12:23:48.871067Z"
    },
    "papermill": {
     "duration": 0.129664,
     "end_time": "2023-01-20T12:23:48.873763",
     "exception": false,
     "start_time": "2023-01-20T12:23:48.744099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Attrition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1677</td>\n",
       "      <td>0.154015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1678</td>\n",
       "      <td>0.226762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1679</td>\n",
       "      <td>0.038524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1680</td>\n",
       "      <td>0.068141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1681</td>\n",
       "      <td>0.612367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>2791</td>\n",
       "      <td>0.073646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>2792</td>\n",
       "      <td>0.006562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>2793</td>\n",
       "      <td>0.025288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>2794</td>\n",
       "      <td>0.019112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>2795</td>\n",
       "      <td>0.003078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1119 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Attrition\n",
       "0     1677   0.154015\n",
       "1     1678   0.226762\n",
       "2     1679   0.038524\n",
       "3     1680   0.068141\n",
       "4     1681   0.612367\n",
       "...    ...        ...\n",
       "1114  2791   0.073646\n",
       "1115  2792   0.006562\n",
       "1116  2793   0.025288\n",
       "1117  2794   0.019112\n",
       "1118  2795   0.003078\n",
       "\n",
       "[1119 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Attrition'] = preds.data[:,0]\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d5c9859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-20T12:23:49.106371Z",
     "iopub.status.busy": "2023-01-20T12:23:49.105995Z",
     "iopub.status.idle": "2023-01-20T12:23:49.116141Z",
     "shell.execute_reply": "2023-01-20T12:23:49.115421Z"
    },
    "papermill": {
     "duration": 0.127934,
     "end_time": "2023-01-20T12:23:49.117861",
     "exception": false,
     "start_time": "2023-01-20T12:23:48.989927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3551.367762,
   "end_time": "2023-01-20T12:23:51.856882",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-01-20T11:24:40.489120",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
